{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9681ddf4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T13:38:18.122241Z",
     "iopub.status.busy": "2024-05-13T13:38:18.121840Z",
     "iopub.status.idle": "2024-05-13T13:38:21.102664Z",
     "shell.execute_reply": "2024-05-13T13:38:21.101472Z"
    },
    "papermill": {
     "duration": 3.001489,
     "end_time": "2024-05-13T13:38:21.105720",
     "exception": false,
     "start_time": "2024-05-13T13:38:18.104231",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gc\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import warnings\n",
    "# turn off performance warning\n",
    "warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a5b675",
   "metadata": {
    "papermill": {
     "duration": 0.014753,
     "end_time": "2024-05-13T13:38:21.135905",
     "exception": false,
     "start_time": "2024-05-13T13:38:21.121152",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Prepare Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1b44abf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T13:38:21.168313Z",
     "iopub.status.busy": "2024-05-13T13:38:21.167666Z",
     "iopub.status.idle": "2024-05-13T13:38:21.174641Z",
     "shell.execute_reply": "2024-05-13T13:38:21.172972Z"
    },
    "papermill": {
     "duration": 0.026155,
     "end_time": "2024-05-13T13:38:21.177066",
     "exception": false,
     "start_time": "2024-05-13T13:38:21.150911",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_data(data_path: str, usecols: [] = None):\n",
    "    if usecols is not None: \n",
    "        df = pd.read_parquet(data_path, columns=usecols)\n",
    "    else: \n",
    "        df = pd.read_parquet(data_path)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23bbbd68",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T13:38:21.211454Z",
     "iopub.status.busy": "2024-05-13T13:38:21.211014Z",
     "iopub.status.idle": "2024-05-13T13:38:41.006781Z",
     "shell.execute_reply": "2024-05-13T13:38:41.005734Z"
    },
    "papermill": {
     "duration": 19.81585,
     "end_time": "2024-05-13T13:38:41.009524",
     "exception": false,
     "start_time": "2024-05-13T13:38:21.193674",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = load_data(data_path=\"/kaggle/input/amex-data-integer-dtypes-parquet-format/train.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe043224",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T13:38:41.041806Z",
     "iopub.status.busy": "2024-05-13T13:38:41.040863Z",
     "iopub.status.idle": "2024-05-13T13:38:46.439585Z",
     "shell.execute_reply": "2024-05-13T13:38:46.438333Z"
    },
    "papermill": {
     "duration": 5.417685,
     "end_time": "2024-05-13T13:38:46.442440",
     "exception": false,
     "start_time": "2024-05-13T13:38:41.024755",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_labels = pd.read_csv('/kaggle/input/amex-default-prediction/train_labels.csv')\n",
    "train_data = pd.merge(train_data, train_labels, on = 'customer_ID', how = 'left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cafa29f",
   "metadata": {
    "papermill": {
     "duration": 0.014854,
     "end_time": "2024-05-13T13:38:46.473261",
     "exception": false,
     "start_time": "2024-05-13T13:38:46.458407",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Preprocessing 1**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7957a671",
   "metadata": {
    "papermill": {
     "duration": 0.014685,
     "end_time": "2024-05-13T13:38:46.503036",
     "exception": false,
     "start_time": "2024-05-13T13:38:46.488351",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**1/ Handle MISSING VALUES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7a35010",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T13:38:46.534773Z",
     "iopub.status.busy": "2024-05-13T13:38:46.534358Z",
     "iopub.status.idle": "2024-05-13T13:38:48.942429Z",
     "shell.execute_reply": "2024-05-13T13:38:48.940944Z"
    },
    "papermill": {
     "duration": 2.42789,
     "end_time": "2024-05-13T13:38:48.945971",
     "exception": false,
     "start_time": "2024-05-13T13:38:46.518081",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['D_88' 'D_110' 'B_39' 'D_73' 'B_42' 'D_134' 'B_29' 'D_132' 'D_76' 'D_42'\n",
      " 'D_142' 'D_53']\n"
     ]
    }
   ],
   "source": [
    "missing_values = train_data.isnull().sum()\n",
    "missing_df = missing_values.to_frame().reset_index().rename(columns={\"index\": \"Feature\", 0: \"Number of missing values\"}).sort_values([\"Number of missing values\"], ascending=False).reset_index(drop=True)\n",
    "missing_df['% missing'] = np.round((missing_df[\"Number of missing values\"] /len(train_data) )*100, 2)\n",
    "missing_70 = missing_df.loc[missing_df['% missing'] > 70, 'Feature'].values\n",
    "del missing_values\n",
    "del missing_df\n",
    "print(missing_70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb35980a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T13:38:48.978993Z",
     "iopub.status.busy": "2024-05-13T13:38:48.978596Z",
     "iopub.status.idle": "2024-05-13T13:38:50.345226Z",
     "shell.execute_reply": "2024-05-13T13:38:50.343995Z"
    },
    "papermill": {
     "duration": 1.386543,
     "end_time": "2024-05-13T13:38:50.348292",
     "exception": false,
     "start_time": "2024-05-13T13:38:48.961749",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# list of features\n",
    "features = train_data.drop(['customer_ID', 'S_2'], axis = 1).columns.to_list()\n",
    "# categorical features:\n",
    "cat_cols = ['B_30', 'B_38', 'D_114', 'D_116', 'D_117', 'D_120', 'D_126', 'D_63', 'D_64', 'D_66', 'D_68']\n",
    "cat_cols = [col for col in cat_cols if col not in missing_70] # make sure dropped columns are not listed in the list\n",
    "    \n",
    "# numerical features:\n",
    "num_features = [col for col in features if col not in cat_cols and col not in missing_70 and col != \"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74d5e3bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T13:38:50.381845Z",
     "iopub.status.busy": "2024-05-13T13:38:50.381457Z",
     "iopub.status.idle": "2024-05-13T13:38:50.389752Z",
     "shell.execute_reply": "2024-05-13T13:38:50.388315Z"
    },
    "papermill": {
     "duration": 0.02811,
     "end_time": "2024-05-13T13:38:50.392264",
     "exception": false,
     "start_time": "2024-05-13T13:38:50.364154",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocessing(df: pd.DataFrame):\n",
    "    # drop columns with >70% values missed\n",
    "    processed_data = df.drop(missing_70, axis = 1)\n",
    "   \n",
    "    # handle missing values: \n",
    "    # impute missing values for numerical features\n",
    "    processed_data[num_features] = df[num_features].fillna(df[num_features].mean())\n",
    "    # impute missing values for categorical features\n",
    "    for col in cat_cols:\n",
    "        processed_data[col] = df[col].fillna(df[col].mode()[0])\n",
    "    # drop rows with missing values if any\n",
    "    processed_data.dropna(inplace = True)\n",
    "    print('preprocessing done')\n",
    "    \n",
    "    return processed_data\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25ffa4a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T13:38:50.424477Z",
     "iopub.status.busy": "2024-05-13T13:38:50.424063Z",
     "iopub.status.idle": "2024-05-13T13:39:05.498033Z",
     "shell.execute_reply": "2024-05-13T13:39:05.497193Z"
    },
    "papermill": {
     "duration": 15.092905,
     "end_time": "2024-05-13T13:39:05.500417",
     "exception": false,
     "start_time": "2024-05-13T13:38:50.407512",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing done\n"
     ]
    }
   ],
   "source": [
    "pro_train = preprocessing(train_data)\n",
    "del train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5c2e79",
   "metadata": {
    "papermill": {
     "duration": 0.015272,
     "end_time": "2024-05-13T13:39:05.531478",
     "exception": false,
     "start_time": "2024-05-13T13:39:05.516206",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**2/ One-Hot Encoding for categorical features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b2af789",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T13:39:05.564223Z",
     "iopub.status.busy": "2024-05-13T13:39:05.563312Z",
     "iopub.status.idle": "2024-05-13T13:39:05.887579Z",
     "shell.execute_reply": "2024-05-13T13:39:05.886364Z"
    },
    "papermill": {
     "duration": 0.34337,
     "end_time": "2024-05-13T13:39:05.890231",
     "exception": false,
     "start_time": "2024-05-13T13:39:05.546861",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'B_30': {0: 0, 1: 1, 2: 2, -1: 3},\n",
       " 'B_38': {1: 0, 2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6, -1: 7},\n",
       " 'D_114': {0: 0, 1: 1, -1: 2},\n",
       " 'D_116': {0: 0, 1: 1, -1: 2},\n",
       " 'D_117': {0: 0, 2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6, -1: 7},\n",
       " 'D_120': {0: 0, 1: 1, -1: 2},\n",
       " 'D_126': {0: 0, 1: 1, 2: 2, -1: 3},\n",
       " 'D_63': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5},\n",
       " 'D_64': {0: 0, 1: 1, 2: 2, 3: 3, -1: 4},\n",
       " 'D_66': {0: 0, 1: 1, -1: 2},\n",
       " 'D_68': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, -1: 7}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_categories = {}\n",
    "for col in cat_cols:\n",
    "    unique_categories[col] = set(pro_train[col].unique()) \n",
    "\n",
    "# Combine unique categories and create a mapping to integers\n",
    "category_to_int = {col: {category: i for i, category in enumerate(categories)} for col, categories in unique_categories.items()}\n",
    "category_to_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9fae75c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T13:39:05.923891Z",
     "iopub.status.busy": "2024-05-13T13:39:05.923481Z",
     "iopub.status.idle": "2024-05-13T13:39:05.929352Z",
     "shell.execute_reply": "2024-05-13T13:39:05.928318Z"
    },
    "papermill": {
     "duration": 0.025251,
     "end_time": "2024-05-13T13:39:05.931512",
     "exception": false,
     "start_time": "2024-05-13T13:39:05.906261",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def one_hot_encoding(df, categorical_features, category_to_int):\n",
    "    df[categorical_features] = df[categorical_features].apply(lambda col: col.map(category_to_int[col.name]))\n",
    "    df = pd.get_dummies(df, columns=categorical_features)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2bd41e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T13:39:05.964493Z",
     "iopub.status.busy": "2024-05-13T13:39:05.963725Z",
     "iopub.status.idle": "2024-05-13T13:39:10.700076Z",
     "shell.execute_reply": "2024-05-13T13:39:10.698639Z"
    },
    "papermill": {
     "duration": 4.755957,
     "end_time": "2024-05-13T13:39:10.702872",
     "exception": false,
     "start_time": "2024-05-13T13:39:05.946915",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pro_train = one_hot_encoding(pro_train, cat_cols, category_to_int)\n",
    "new_cat_cols = [x for x in pro_train.columns if x not in num_features and x != \"S_2\" and x != \"customer_ID\" and x != \"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef056862",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T13:39:10.738795Z",
     "iopub.status.busy": "2024-05-13T13:39:10.738379Z",
     "iopub.status.idle": "2024-05-13T13:39:10.946942Z",
     "shell.execute_reply": "2024-05-13T13:39:10.945761Z"
    },
    "papermill": {
     "duration": 0.229656,
     "end_time": "2024-05-13T13:39:10.949624",
     "exception": false,
     "start_time": "2024-05-13T13:39:10.719968",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>B_30_0</th>\n",
       "      <th>B_30_1</th>\n",
       "      <th>B_30_2</th>\n",
       "      <th>B_30_3</th>\n",
       "      <th>B_38_0</th>\n",
       "      <th>B_38_1</th>\n",
       "      <th>B_38_2</th>\n",
       "      <th>B_38_3</th>\n",
       "      <th>B_38_4</th>\n",
       "      <th>B_38_5</th>\n",
       "      <th>...</th>\n",
       "      <th>D_66_1</th>\n",
       "      <th>D_66_2</th>\n",
       "      <th>D_68_0</th>\n",
       "      <th>D_68_1</th>\n",
       "      <th>D_68_2</th>\n",
       "      <th>D_68_3</th>\n",
       "      <th>D_68_4</th>\n",
       "      <th>D_68_5</th>\n",
       "      <th>D_68_6</th>\n",
       "      <th>D_68_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   B_30_0  B_30_1  B_30_2  B_30_3  B_38_0  B_38_1  B_38_2  B_38_3  B_38_4  \\\n",
       "0    True   False   False   False   False    True   False   False   False   \n",
       "1    True   False   False   False   False    True   False   False   False   \n",
       "2    True   False   False   False   False    True   False   False   False   \n",
       "3    True   False   False   False   False    True   False   False   False   \n",
       "4    True   False   False   False   False    True   False   False   False   \n",
       "\n",
       "   B_38_5  ...  D_66_1  D_66_2  D_68_0  D_68_1  D_68_2  D_68_3  D_68_4  \\\n",
       "0   False  ...   False    True   False   False   False   False   False   \n",
       "1   False  ...   False    True   False   False   False   False   False   \n",
       "2   False  ...   False    True   False   False   False   False   False   \n",
       "3   False  ...   False    True   False   False   False   False   False   \n",
       "4   False  ...   False    True   False   False   False   False   False   \n",
       "\n",
       "   D_68_5  D_68_6  D_68_7  \n",
       "0   False    True   False  \n",
       "1   False    True   False  \n",
       "2   False    True   False  \n",
       "3   False    True   False  \n",
       "4   False    True   False  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pro_train[new_cat_cols].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a98556",
   "metadata": {
    "papermill": {
     "duration": 0.015684,
     "end_time": "2024-05-13T13:39:10.981326",
     "exception": false,
     "start_time": "2024-05-13T13:39:10.965642",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**DATA AGGREGATION (transaction level to customer level)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b68e6cdf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T13:39:11.018383Z",
     "iopub.status.busy": "2024-05-13T13:39:11.017104Z",
     "iopub.status.idle": "2024-05-13T13:39:11.030737Z",
     "shell.execute_reply": "2024-05-13T13:39:11.029321Z"
    },
    "papermill": {
     "duration": 0.036172,
     "end_time": "2024-05-13T13:39:11.033815",
     "exception": false,
     "start_time": "2024-05-13T13:39:10.997643",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def aggregation(df: pd.DataFrame, labels: pd.DataFrame = None):\n",
    "    \n",
    "    print(\"start aggregating numerical features ..\")\n",
    "    # numerical features aggregated by time period\n",
    "    df_num_agg = df.groupby('customer_ID')[num_features].agg(['mean', 'std', 'min', 'max', 'first', 'last'])\n",
    "    df_num_agg.columns = ['_'.join(x) for x in df_num_agg.columns]\n",
    "    df_num_agg.reset_index()\n",
    "    \n",
    "    print('start creating lag features ..')\n",
    "    # Lag Features: First / Last statemeants\n",
    "    for col in df_num_agg.columns:\n",
    "        if 'last' in col and col.replace('last', 'first') in df_num_agg.columns:\n",
    "            df_num_agg[col + '_lag_sub'] = df_num_agg[col] - df_num_agg[col.replace('last', 'first')]\n",
    "            # df_num_agg[col + '_lag_div'] = df_num_agg[col] / df_num_agg[col.replace('last', 'first')]\n",
    "            \n",
    "    print('start aggregating categorical features ..')\n",
    "    # categorical feartures aggregated by time period\n",
    "    df_cat_agg = df.groupby('customer_ID')[new_cat_cols].agg(['count', 'first', 'last', 'nunique'])\n",
    "    df_cat_agg.columns = ['_'.join(x) for x in df_cat_agg.columns]\n",
    "    df_cat_agg.reset_index()\n",
    "    \n",
    "    # merge sub-dataframe\n",
    "    if labels is not None:\n",
    "        df_agg = df_num_agg.merge(df_cat_agg, how = 'inner', on = 'customer_ID').merge(labels, how = 'inner', on = 'customer_ID')\n",
    "    else:\n",
    "        df_agg = df_num_agg.merge(df_cat_agg, how = 'inner', on = 'customer_ID')\n",
    "    # drop customer_ID after merging\n",
    "    df_agg.drop('customer_ID', axis = 1, inplace = True)\n",
    "    \n",
    "    del df_num_agg, df_cat_agg\n",
    "    \n",
    "    print('feature engineering completed')\n",
    "    print('Dimensions after egineering: ', df_agg.shape )\n",
    "    \n",
    "    return df_agg\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e8b7b2b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T13:39:11.068991Z",
     "iopub.status.busy": "2024-05-13T13:39:11.068530Z",
     "iopub.status.idle": "2024-05-13T13:40:47.767884Z",
     "shell.execute_reply": "2024-05-13T13:40:47.766443Z"
    },
    "papermill": {
     "duration": 96.720263,
     "end_time": "2024-05-13T13:40:47.770416",
     "exception": false,
     "start_time": "2024-05-13T13:39:11.050153",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start aggregating numerical features ..\n",
      "start creating lag features ..\n",
      "start aggregating categorical features ..\n",
      "feature engineering completed\n",
      "Dimensions after egineering:  (458913, 1376)\n"
     ]
    }
   ],
   "source": [
    "agg_train = aggregation(pro_train.drop(columns=['target']), train_labels)\n",
    "del pro_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "514ff242",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T13:40:47.804762Z",
     "iopub.status.busy": "2024-05-13T13:40:47.804360Z",
     "iopub.status.idle": "2024-05-13T13:40:47.830679Z",
     "shell.execute_reply": "2024-05-13T13:40:47.829546Z"
    },
    "papermill": {
     "duration": 0.046397,
     "end_time": "2024-05-13T13:40:47.833023",
     "exception": false,
     "start_time": "2024-05-13T13:40:47.786626",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P_2_mean</th>\n",
       "      <th>P_2_std</th>\n",
       "      <th>P_2_min</th>\n",
       "      <th>P_2_max</th>\n",
       "      <th>P_2_first</th>\n",
       "      <th>P_2_last</th>\n",
       "      <th>D_39_mean</th>\n",
       "      <th>D_39_std</th>\n",
       "      <th>D_39_min</th>\n",
       "      <th>D_39_max</th>\n",
       "      <th>...</th>\n",
       "      <th>D_68_5_nunique</th>\n",
       "      <th>D_68_6_count</th>\n",
       "      <th>D_68_6_first</th>\n",
       "      <th>D_68_6_last</th>\n",
       "      <th>D_68_6_nunique</th>\n",
       "      <th>D_68_7_count</th>\n",
       "      <th>D_68_7_first</th>\n",
       "      <th>D_68_7_last</th>\n",
       "      <th>D_68_7_nunique</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.933824</td>\n",
       "      <td>0.024194</td>\n",
       "      <td>0.868580</td>\n",
       "      <td>0.960384</td>\n",
       "      <td>0.938469</td>\n",
       "      <td>0.934745</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.832050</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.899820</td>\n",
       "      <td>0.022119</td>\n",
       "      <td>0.861109</td>\n",
       "      <td>0.929122</td>\n",
       "      <td>0.929122</td>\n",
       "      <td>0.880519</td>\n",
       "      <td>7.153846</td>\n",
       "      <td>6.743468</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.878454</td>\n",
       "      <td>0.028911</td>\n",
       "      <td>0.797670</td>\n",
       "      <td>0.904482</td>\n",
       "      <td>0.876615</td>\n",
       "      <td>0.880875</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.598969</td>\n",
       "      <td>0.020107</td>\n",
       "      <td>0.567442</td>\n",
       "      <td>0.623392</td>\n",
       "      <td>0.567442</td>\n",
       "      <td>0.621776</td>\n",
       "      <td>1.538462</td>\n",
       "      <td>3.017046</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.891679</td>\n",
       "      <td>0.042325</td>\n",
       "      <td>0.805045</td>\n",
       "      <td>0.940382</td>\n",
       "      <td>0.936842</td>\n",
       "      <td>0.871900</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1376 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   P_2_mean   P_2_std   P_2_min   P_2_max  P_2_first  P_2_last  D_39_mean  \\\n",
       "0  0.933824  0.024194  0.868580  0.960384   0.938469  0.934745   0.230769   \n",
       "1  0.899820  0.022119  0.861109  0.929122   0.929122  0.880519   7.153846   \n",
       "2  0.878454  0.028911  0.797670  0.904482   0.876615  0.880875   0.000000   \n",
       "3  0.598969  0.020107  0.567442  0.623392   0.567442  0.621776   1.538462   \n",
       "4  0.891679  0.042325  0.805045  0.940382   0.936842  0.871900   0.000000   \n",
       "\n",
       "   D_39_std  D_39_min  D_39_max  ...  D_68_5_nunique  D_68_6_count  \\\n",
       "0  0.832050         0         3  ...               1            13   \n",
       "1  6.743468         0        19  ...               1            13   \n",
       "2  0.000000         0         0  ...               1            13   \n",
       "3  3.017046         0         9  ...               1            13   \n",
       "4  0.000000         0         0  ...               1            13   \n",
       "\n",
       "   D_68_6_first  D_68_6_last  D_68_6_nunique  D_68_7_count  D_68_7_first  \\\n",
       "0          True         True               1            13         False   \n",
       "1          True         True               1            13         False   \n",
       "2          True         True               1            13         False   \n",
       "3         False        False               2            13         False   \n",
       "4          True         True               1            13         False   \n",
       "\n",
       "   D_68_7_last  D_68_7_nunique  target  \n",
       "0        False               1       0  \n",
       "1        False               1       0  \n",
       "2        False               1       0  \n",
       "3        False               1       0  \n",
       "4        False               1       0  \n",
       "\n",
       "[5 rows x 1376 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c84a18d",
   "metadata": {
    "papermill": {
     "duration": 0.016466,
     "end_time": "2024-05-13T13:40:47.866158",
     "exception": false,
     "start_time": "2024-05-13T13:40:47.849692",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Handle MISSING VALUES 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1a7e1187",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T13:40:47.963151Z",
     "iopub.status.busy": "2024-05-13T13:40:47.961999Z",
     "iopub.status.idle": "2024-05-13T13:40:48.584466Z",
     "shell.execute_reply": "2024-05-13T13:40:48.583368Z"
    },
    "papermill": {
     "duration": 0.643327,
     "end_time": "2024-05-13T13:40:48.587003",
     "exception": false,
     "start_time": "2024-05-13T13:40:47.943676",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Number of missing values</th>\n",
       "      <th>% missing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D_135_std</td>\n",
       "      <td>5120</td>\n",
       "      <td>1.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D_56_std</td>\n",
       "      <td>5120</td>\n",
       "      <td>1.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S_8_std</td>\n",
       "      <td>5120</td>\n",
       "      <td>1.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>R_22_std</td>\n",
       "      <td>5120</td>\n",
       "      <td>1.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B_8_std</td>\n",
       "      <td>5120</td>\n",
       "      <td>1.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>D_96_std</td>\n",
       "      <td>5120</td>\n",
       "      <td>1.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>D_105_std</td>\n",
       "      <td>5120</td>\n",
       "      <td>1.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>B_26_std</td>\n",
       "      <td>5120</td>\n",
       "      <td>1.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>B_4_std</td>\n",
       "      <td>5120</td>\n",
       "      <td>1.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>D_71_std</td>\n",
       "      <td>5120</td>\n",
       "      <td>1.12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>165 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Feature  Number of missing values  % missing\n",
       "0    D_135_std                      5120       1.12\n",
       "1     D_56_std                      5120       1.12\n",
       "2      S_8_std                      5120       1.12\n",
       "3     R_22_std                      5120       1.12\n",
       "4      B_8_std                      5120       1.12\n",
       "..         ...                       ...        ...\n",
       "160   D_96_std                      5120       1.12\n",
       "161  D_105_std                      5120       1.12\n",
       "162   B_26_std                      5120       1.12\n",
       "163    B_4_std                      5120       1.12\n",
       "164   D_71_std                      5120       1.12\n",
       "\n",
       "[165 rows x 3 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_values = agg_train.isnull().sum()\n",
    "missing_df = missing_values.to_frame().reset_index().rename(columns={\"index\": \"Feature\", 0: \"Number of missing values\"}).sort_values([\"Number of missing values\"], ascending=False).reset_index(drop=True)\n",
    "missing_df['% missing'] = np.round((missing_df[\"Number of missing values\"] /len(agg_train) )*100, 2)\n",
    "missing_df = missing_df[missing_df['% missing'] != 0]\n",
    "missing_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d9ce74",
   "metadata": {
    "papermill": {
     "duration": 0.016795,
     "end_time": "2024-05-13T13:40:48.620750",
     "exception": false,
     "start_time": "2024-05-13T13:40:48.603955",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Obseravtion: the % of missing values for _std columns is only 1.12%, then i decide to drop all the rows with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "880c0383",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T13:40:48.656838Z",
     "iopub.status.busy": "2024-05-13T13:40:48.656465Z",
     "iopub.status.idle": "2024-05-13T13:40:49.645009Z",
     "shell.execute_reply": "2024-05-13T13:40:49.643866Z"
    },
    "papermill": {
     "duration": 1.009569,
     "end_time": "2024-05-13T13:40:49.647680",
     "exception": false,
     "start_time": "2024-05-13T13:40:48.638111",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 453793 entries, 0 to 458912\n",
      "Columns: 1376 entries, P_2_mean to target\n",
      "dtypes: bool(110), float32(567), float64(168), int16(45), int64(111), int8(375)\n",
      "memory usage: 2.1 GB\n"
     ]
    }
   ],
   "source": [
    "agg_train.dropna(subset=['D_135_std'], inplace=True)\n",
    "agg_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fe4d38ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T13:40:49.685244Z",
     "iopub.status.busy": "2024-05-13T13:40:49.684874Z",
     "iopub.status.idle": "2024-05-13T13:40:49.689646Z",
     "shell.execute_reply": "2024-05-13T13:40:49.688506Z"
    },
    "papermill": {
     "duration": 0.026283,
     "end_time": "2024-05-13T13:40:49.691966",
     "exception": false,
     "start_time": "2024-05-13T13:40:49.665683",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "del missing_values\n",
    "del missing_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836bb79a",
   "metadata": {
    "papermill": {
     "duration": 0.016854,
     "end_time": "2024-05-13T13:40:49.725968",
     "exception": false,
     "start_time": "2024-05-13T13:40:49.709114",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Convert boolean values to numerical data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "60511cab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T13:40:49.762650Z",
     "iopub.status.busy": "2024-05-13T13:40:49.762247Z",
     "iopub.status.idle": "2024-05-13T13:40:50.466428Z",
     "shell.execute_reply": "2024-05-13T13:40:50.465358Z"
    },
    "papermill": {
     "duration": 0.725646,
     "end_time": "2024-05-13T13:40:50.469314",
     "exception": false,
     "start_time": "2024-05-13T13:40:49.743668",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "features= agg_train.drop(['target'], axis = 1).columns.to_list()\n",
    "cat_cols = [col for col in features if agg_train[col].dtype == 'O' or agg_train[col].dtype == 'bool']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "626fff46",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T13:40:50.505831Z",
     "iopub.status.busy": "2024-05-13T13:40:50.505453Z",
     "iopub.status.idle": "2024-05-13T13:41:52.223939Z",
     "shell.execute_reply": "2024-05-13T13:41:52.222666Z"
    },
    "papermill": {
     "duration": 61.755958,
     "end_time": "2024-05-13T13:41:52.242666",
     "exception": false,
     "start_time": "2024-05-13T13:40:50.486708",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done!\n"
     ]
    }
   ],
   "source": [
    "# Define the conversion function\n",
    "def convert_to_numeric(value):\n",
    "    mapping = {\"[True]\": 1, \"[False]\": 0}\n",
    "    if isinstance(value, bool):\n",
    "        return int(value)\n",
    "    elif isinstance(value, str):\n",
    "        return mapping.get(value, value)\n",
    "    else:\n",
    "        return value\n",
    "\n",
    "# Apply the conversion function to columns with object and boolean dtype\n",
    "for col in cat_cols:\n",
    "    agg_train[col] = agg_train[col].apply(lambda x: convert_to_numeric(x))\n",
    "print(\"done!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f00bce",
   "metadata": {
    "papermill": {
     "duration": 0.019815,
     "end_time": "2024-05-13T13:41:52.279897",
     "exception": false,
     "start_time": "2024-05-13T13:41:52.260082",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Feature Selection**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497377c8",
   "metadata": {
    "papermill": {
     "duration": 0.017666,
     "end_time": "2024-05-13T13:41:52.314908",
     "exception": false,
     "start_time": "2024-05-13T13:41:52.297242",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**1/ Correlation Matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c6df76cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T13:41:52.351983Z",
     "iopub.status.busy": "2024-05-13T13:41:52.351566Z",
     "iopub.status.idle": "2024-05-13T13:41:52.355990Z",
     "shell.execute_reply": "2024-05-13T13:41:52.355110Z"
    },
    "papermill": {
     "duration": 0.026113,
     "end_time": "2024-05-13T13:41:52.358196",
     "exception": false,
     "start_time": "2024-05-13T13:41:52.332083",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# correlation_matrix = agg_train[features].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b826f3b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T13:41:52.394585Z",
     "iopub.status.busy": "2024-05-13T13:41:52.394156Z",
     "iopub.status.idle": "2024-05-13T13:41:52.401887Z",
     "shell.execute_reply": "2024-05-13T13:41:52.400785Z"
    },
    "papermill": {
     "duration": 0.028631,
     "end_time": "2024-05-13T13:41:52.404160",
     "exception": false,
     "start_time": "2024-05-13T13:41:52.375529",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# Auto drop columns with high correlation coeffition (>80%)\\ncolumns = np.full((correlation_matrix.shape[0],), True, dtype=bool)\\nfor i in range(correlation_matrix.shape[0]):\\n    for j in range(i+1, correlation_matrix.shape[0]):\\n        if correlation_matrix.iloc[i,j] >= 0.8:\\n            if columns[j]:\\n                columns[j] = False\\nselected_columns = agg_train.drop(columns=['target']).columns[columns]\\n\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Auto drop columns with high correlation coeffition (>80%)\n",
    "columns = np.full((correlation_matrix.shape[0],), True, dtype=bool)\n",
    "for i in range(correlation_matrix.shape[0]):\n",
    "    for j in range(i+1, correlation_matrix.shape[0]):\n",
    "        if correlation_matrix.iloc[i,j] >= 0.8:\n",
    "            if columns[j]:\n",
    "                columns[j] = False\n",
    "selected_columns = agg_train.drop(columns=['target']).columns[columns]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dae02e7f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T13:41:52.441187Z",
     "iopub.status.busy": "2024-05-13T13:41:52.440171Z",
     "iopub.status.idle": "2024-05-13T13:41:52.445006Z",
     "shell.execute_reply": "2024-05-13T13:41:52.444202Z"
    },
    "papermill": {
     "duration": 0.025508,
     "end_time": "2024-05-13T13:41:52.447246",
     "exception": false,
     "start_time": "2024-05-13T13:41:52.421738",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# selected_columns = selected_columns.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8b08ee32",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T13:41:52.483731Z",
     "iopub.status.busy": "2024-05-13T13:41:52.483050Z",
     "iopub.status.idle": "2024-05-13T13:41:52.489818Z",
     "shell.execute_reply": "2024-05-13T13:41:52.488771Z"
    },
    "papermill": {
     "duration": 0.027695,
     "end_time": "2024-05-13T13:41:52.492060",
     "exception": false,
     "start_time": "2024-05-13T13:41:52.464365",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nprint(\"selected features after correlation filtering at 80%: \", len(selected_columns))\\n# Convert array to a list of strings with commas and single quotes\\narray_str = \\', \\'.join(f\"\\'{elem}\\'\" for elem in selected_columns)\\nprint(f\"[{array_str}]\")\\n'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "print(\"selected features after correlation filtering at 80%: \", len(selected_columns))\n",
    "# Convert array to a list of strings with commas and single quotes\n",
    "array_str = ', '.join(f\"'{elem}'\" for elem in selected_columns)\n",
    "print(f\"[{array_str}]\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1eedca3d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T13:41:52.529124Z",
     "iopub.status.busy": "2024-05-13T13:41:52.528762Z",
     "iopub.status.idle": "2024-05-13T13:41:52.654751Z",
     "shell.execute_reply": "2024-05-13T13:41:52.653115Z"
    },
    "papermill": {
     "duration": 0.147633,
     "end_time": "2024-05-13T13:41:52.657449",
     "exception": false,
     "start_time": "2024-05-13T13:41:52.509816",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of selected features:  720\n"
     ]
    }
   ],
   "source": [
    "selected_columns = ['P_2_mean', 'P_2_std', 'D_39_mean', 'D_39_min', 'D_39_first', 'D_39_last', 'B_1_mean', 'B_1_std', 'B_2_mean', 'B_2_std', 'B_2_max', 'B_2_first', 'R_1_mean', 'R_1_min', 'R_1_first', 'R_1_last', 'S_3_mean', 'S_3_std', 'S_3_first', 'D_41_mean', 'D_41_std', 'D_41_min', 'D_41_first', 'B_3_mean', 'B_3_std', 'D_43_mean', 'D_43_std', 'D_43_first', 'D_43_last', 'D_44_mean', 'D_44_std', 'B_4_mean', 'B_4_std', 'D_45_mean', 'D_45_std', 'B_5_mean', 'B_5_min', 'B_5_first', 'B_5_last', 'R_2_mean', 'R_2_std', 'R_2_min', 'R_2_first', 'R_2_last', 'D_46_mean', 'D_46_std', 'D_46_min', 'D_46_first', 'D_46_last', 'D_47_mean', 'D_47_std', 'D_48_mean', 'D_48_std', 'D_49_mean', 'D_49_std', 'D_49_min', 'B_6_mean', 'B_6_min', 'B_6_first', 'B_6_last', 'B_7_mean', 'B_7_std', 'B_8_mean', 'B_8_std', 'D_50_mean', 'D_50_std', 'D_50_min', 'D_50_first', 'D_50_last', 'D_51_mean', 'D_51_std', 'B_9_mean', 'B_9_std', 'R_3_mean', 'R_3_std', 'R_3_min', 'R_3_first', 'R_3_last', 'D_52_mean', 'D_52_std', 'P_3_mean', 'P_3_std', 'P_3_min', 'P_3_max', 'P_3_first', 'P_3_last', 'B_10_mean', 'B_10_min', 'B_10_first', 'B_10_last', 'S_5_mean', 'S_5_min', 'S_5_first', 'S_5_last', 'S_6_mean', 'S_6_std', 'S_6_max', 'S_6_first', 'D_54_mean', 'D_54_std', 'D_54_min', 'D_54_max', 'D_54_first', 'R_4_min', 'R_4_first', 'R_4_last', 'B_12_mean', 'B_12_std', 'S_8_mean', 'S_8_std', 'D_55_std', 'D_56_mean', 'D_56_std', 'R_5_min', 'R_5_first', 'R_5_last', 'D_58_mean', 'D_58_std', 'S_9_mean', 'S_9_min', 'S_9_first', 'S_9_last', 'B_14_mean', 'D_59_mean', 'D_59_std', 'D_59_min', 'D_60_mean', 'D_60_std', 'D_61_std', 'S_11_mean', 'S_11_std', 'S_11_min', 'S_11_max', 'S_11_first', 'S_11_last', 'D_62_mean', 'D_62_std', 'D_65_mean', 'D_65_min', 'D_65_first', 'D_65_last', 'B_16_mean', 'B_16_std', 'B_17_mean', 'B_17_std', 'B_17_min', 'B_17_max', 'B_17_first', 'B_17_last', 'B_18_std', 'B_19_std', 'B_20_std', 'S_12_mean', 'S_12_min', 'S_12_first', 'S_12_last', 'R_6_mean', 'R_6_min', 'R_6_first', 'R_6_last', 'S_13_mean', 'S_13_std', 'B_21_mean', 'B_21_min', 'B_21_first', 'B_21_last', 'D_69_mean', 'D_69_min', 'D_69_last', 'B_22_std', 'B_22_min', 'B_22_first', 'D_70_mean', 'D_70_std', 'D_70_min', 'D_70_first', 'D_70_last', 'D_71_mean', 'D_71_std', 'D_71_min', 'D_72_mean', 'D_72_std', 'D_72_min', 'D_72_first', 'S_15_mean', 'S_15_std', 'S_15_min', 'S_15_max', 'S_15_first', 'S_15_last', 'P_4_mean', 'P_4_std', 'B_24_mean', 'B_24_min', 'B_24_first', 'R_7_mean', 'R_7_min', 'R_7_first', 'R_7_last', 'D_77_std', 'B_25_mean', 'B_25_std', 'B_26_mean', 'B_26_min', 'B_26_first', 'B_26_last', 'D_78_mean', 'D_78_std', 'D_78_min', 'D_78_first', 'D_79_mean', 'D_79_std', 'D_79_min', 'R_8_min', 'R_8_first', 'R_9_mean', 'R_9_std', 'S_16_mean', 'S_16_min', 'S_16_first', 'S_16_last', 'D_80_mean', 'D_80_std', 'D_80_min', 'R_10_min', 'R_10_first', 'R_10_last', 'R_11_mean', 'R_11_min', 'R_11_first', 'R_11_last', 'B_27_mean', 'B_27_std', 'B_27_min', 'B_27_first', 'B_27_last', 'D_81_mean', 'D_81_std', 'D_81_min', 'D_81_first', 'D_82_mean', 'D_82_std', 'S_17_mean', 'S_17_min', 'S_17_first', 'S_17_last', 'R_12_mean', 'R_12_std', 'R_12_max', 'R_12_first', 'B_28_mean', 'R_13_min', 'R_13_first', 'R_13_last', 'D_83_mean', 'D_83_std', 'D_83_min', 'R_14_mean', 'R_14_min', 'R_14_first', 'R_14_last', 'R_15_mean', 'R_15_min', 'R_15_first', 'R_15_last', 'D_84_min', 'D_84_first', 'R_16_mean', 'R_16_min', 'R_16_first', 'R_16_last', 'S_18_mean', 'S_18_std', 'S_18_min', 'S_18_last', 'D_86_mean', 'D_86_std', 'D_87_mean', 'D_87_std', 'D_87_min', 'D_87_first', 'R_17_min', 'R_17_first', 'R_17_last', 'R_18_mean', 'R_18_min', 'R_18_first', 'R_18_last', 'B_31_mean', 'B_31_std', 'B_31_max', 'B_31_first', 'B_31_last', 'S_19_mean', 'S_19_std', 'S_19_min', 'S_19_first', 'S_19_last', 'R_19_mean', 'R_19_std', 'B_32_mean', 'B_32_std', 'B_32_min', 'B_32_first', 'B_32_last', 'S_20_mean', 'S_20_std', 'S_20_min', 'S_20_first', 'S_20_last', 'R_20_min', 'R_20_first', 'R_20_last', 'R_21_std', 'R_21_min', 'R_21_first', 'R_21_last', 'D_89_mean', 'D_89_last', 'R_22_mean', 'R_22_min', 'R_22_first', 'R_22_last', 'R_23_mean', 'R_23_min', 'R_23_first', 'R_23_last', 'D_91_mean', 'D_91_std', 'D_91_min', 'D_92_mean', 'D_92_std', 'D_92_min', 'D_93_mean', 'D_93_std', 'D_93_min', 'D_94_mean', 'D_94_std', 'D_94_min', 'R_24_mean', 'R_24_min', 'R_24_first', 'R_24_last', 'R_25_mean', 'R_25_min', 'R_25_first', 'R_25_last', 'D_96_mean', 'D_96_std', 'D_96_min', 'D_96_first', 'D_96_last', 'S_22_mean', 'S_22_std', 'S_22_min', 'S_22_max', 'S_22_first', 'S_22_last', 'S_23_mean', 'S_23_std', 'S_23_min', 'S_23_first', 'S_23_last', 'S_25_mean', 'S_25_std', 'S_25_max', 'S_25_first', 'S_25_last', 'S_26_mean', 'D_102_mean', 'D_102_std', 'D_103_mean', 'D_103_std', 'D_103_min', 'D_105_mean', 'D_105_std', 'D_106_mean', 'D_106_min', 'D_106_first', 'B_36_mean', 'B_36_std', 'B_36_min', 'R_26_mean', 'R_26_std', 'R_27_mean', 'R_27_std', 'D_108_mean', 'D_108_min', 'D_108_first', 'D_108_last', 'D_109_mean', 'D_109_std', 'D_109_min', 'D_112_mean', 'D_112_std', 'D_112_max', 'D_112_first', 'D_112_last', 'B_40_mean', 'B_40_min', 'B_40_first', 'B_40_last', 'S_27_mean', 'S_27_std', 'S_27_min', 'S_27_first', 'S_27_last', 'D_113_mean', 'D_113_std', 'D_115_mean', 'D_115_std', 'D_118_std', 'D_121_mean', 'D_121_std', 'D_122_mean', 'D_122_std', 'D_123_mean', 'D_123_std', 'D_123_max', 'D_123_last', 'D_124_mean', 'D_124_std', 'D_125_mean', 'D_125_std', 'D_125_max', 'D_125_first', 'D_125_last', 'D_127_mean', 'D_127_std', 'D_127_min', 'D_128_mean', 'D_128_std', 'D_129_mean', 'D_129_std', 'D_129_min', 'B_41_mean', 'B_41_min', 'B_41_first', 'D_130_mean', 'D_130_std', 'D_131_std', 'D_133_mean', 'D_133_std', 'D_133_min', 'D_133_first', 'R_28_mean', 'R_28_std', 'R_28_min', 'R_28_first', 'R_28_last', 'D_135_mean', 'D_135_min', 'D_135_first', 'D_135_last', 'D_139_mean', 'D_139_std', 'D_139_min', 'D_140_mean', 'D_140_std', 'D_140_min', 'D_140_last', 'D_144_mean', 'D_144_std', 'D_145_mean', 'D_145_std', 'B_1_last_lag_sub', 'B_2_last_lag_sub', 'R_1_last_lag_sub', 'S_3_last_lag_sub', 'B_3_last_lag_sub', 'D_43_last_lag_sub', 'D_44_last_lag_sub', 'B_4_last_lag_sub', 'D_45_last_lag_sub', 'B_5_last_lag_sub', 'D_46_last_lag_sub', 'D_47_last_lag_sub', 'D_48_last_lag_sub', 'D_49_last_lag_sub', 'B_6_last_lag_sub', 'B_7_last_lag_sub', 'B_8_last_lag_sub', 'D_50_last_lag_sub', 'D_51_last_lag_sub', 'B_9_last_lag_sub', 'R_3_last_lag_sub', 'D_52_last_lag_sub', 'B_10_last_lag_sub', 'S_5_last_lag_sub', 'S_6_last_lag_sub', 'B_12_last_lag_sub', 'S_8_last_lag_sub', 'D_55_last_lag_sub', 'D_56_last_lag_sub', 'B_13_last_lag_sub', 'D_58_last_lag_sub', 'S_9_last_lag_sub', 'B_14_last_lag_sub', 'D_60_last_lag_sub', 'D_61_last_lag_sub', 'S_11_last_lag_sub', 'D_62_last_lag_sub', 'B_16_last_lag_sub', 'B_17_last_lag_sub', 'B_18_last_lag_sub', 'B_19_last_lag_sub', 'B_20_last_lag_sub', 'S_12_last_lag_sub', 'S_13_last_lag_sub', 'B_21_last_lag_sub', 'D_69_last_lag_sub', 'B_22_last_lag_sub', 'D_70_last_lag_sub', 'D_71_last_lag_sub', 'D_72_last_lag_sub', 'S_15_last_lag_sub', 'P_4_last_lag_sub', 'R_7_last_lag_sub', 'D_77_last_lag_sub', 'B_25_last_lag_sub', 'B_26_last_lag_sub', 'D_78_last_lag_sub', 'D_79_last_lag_sub', 'R_9_last_lag_sub', 'S_16_last_lag_sub', 'D_80_last_lag_sub', 'R_11_last_lag_sub', 'B_27_last_lag_sub', 'D_81_last_lag_sub', 'D_82_last_lag_sub', 'S_17_last_lag_sub', 'R_12_last_lag_sub', 'B_28_last_lag_sub', 'D_83_last_lag_sub', 'R_14_last_lag_sub', 'R_16_last_lag_sub', 'S_18_last_lag_sub', 'D_86_last_lag_sub', 'S_19_last_lag_sub', 'R_19_last_lag_sub', 'B_32_last_lag_sub', 'S_20_last_lag_sub', 'R_21_last_lag_sub', 'D_89_last_lag_sub', 'R_22_last_lag_sub', 'R_23_last_lag_sub', 'D_91_last_lag_sub', 'D_92_last_lag_sub', 'D_93_last_lag_sub', 'D_94_last_lag_sub', 'D_96_last_lag_sub', 'S_22_last_lag_sub', 'S_23_last_lag_sub', 'S_25_last_lag_sub', 'S_26_last_lag_sub', 'D_102_last_lag_sub', 'D_103_last_lag_sub', 'D_104_last_lag_sub', 'D_105_last_lag_sub', 'R_26_last_lag_sub', 'R_27_last_lag_sub', 'D_108_last_lag_sub', 'D_109_last_lag_sub', 'D_112_last_lag_sub', 'B_40_last_lag_sub', 'S_27_last_lag_sub', 'D_113_last_lag_sub', 'D_115_last_lag_sub', 'D_118_last_lag_sub', 'D_121_last_lag_sub', 'D_122_last_lag_sub', 'D_123_last_lag_sub', 'D_125_last_lag_sub', 'D_127_last_lag_sub', 'D_128_last_lag_sub', 'D_129_last_lag_sub', 'B_41_last_lag_sub', 'D_130_last_lag_sub', 'D_131_last_lag_sub', 'D_133_last_lag_sub', 'R_28_last_lag_sub', 'D_135_last_lag_sub', 'D_139_last_lag_sub', 'D_140_last_lag_sub', 'D_141_last_lag_sub', 'D_144_last_lag_sub', 'D_145_last_lag_sub', 'B_30_0_count', 'B_30_0_first', 'B_30_0_last', 'B_30_1_last', 'B_30_2_first', 'B_30_2_last', 'B_30_2_nunique', 'B_30_3_first', 'B_30_3_last', 'B_38_0_first', 'B_38_0_last', 'B_38_0_nunique', 'B_38_1_first', 'B_38_1_last', 'B_38_1_nunique', 'B_38_2_first', 'B_38_2_last', 'B_38_2_nunique', 'B_38_3_first', 'B_38_3_last', 'B_38_3_nunique', 'B_38_4_first', 'B_38_4_last', 'B_38_4_nunique', 'B_38_5_first', 'B_38_5_last', 'B_38_5_nunique', 'B_38_6_first', 'B_38_6_last', 'B_38_6_nunique', 'B_38_7_last', 'D_114_0_first', 'D_114_0_last', 'D_114_0_nunique', 'D_114_1_first', 'D_114_1_last', 'D_114_1_nunique', 'D_114_2_last', 'D_116_0_last', 'D_116_1_first', 'D_116_1_last', 'D_117_0_first', 'D_117_0_last', 'D_117_0_nunique', 'D_117_1_first', 'D_117_1_last', 'D_117_1_nunique', 'D_117_2_first', 'D_117_2_last', 'D_117_2_nunique', 'D_117_3_first', 'D_117_3_last', 'D_117_3_nunique', 'D_117_4_first', 'D_117_4_last', 'D_117_4_nunique', 'D_117_5_first', 'D_117_5_last', 'D_117_5_nunique', 'D_117_6_first', 'D_117_6_last', 'D_117_6_nunique', 'D_120_0_first', 'D_120_0_last', 'D_120_0_nunique', 'D_120_1_first', 'D_120_1_last', 'D_120_1_nunique', 'D_126_0_first', 'D_126_0_last', 'D_126_0_nunique', 'D_126_1_first', 'D_126_1_last', 'D_126_1_nunique', 'D_126_2_first', 'D_126_2_last', 'D_126_2_nunique', 'D_126_3_last', 'D_63_0_nunique', 'D_63_1_first', 'D_63_1_last', 'D_63_1_nunique', 'D_63_2_first', 'D_63_2_last', 'D_63_2_nunique', 'D_63_3_first', 'D_63_3_nunique', 'D_63_4_first', 'D_63_4_last', 'D_63_4_nunique', 'D_63_5_first', 'D_63_5_last', 'D_63_5_nunique', 'D_64_0_first', 'D_64_0_last', 'D_64_0_nunique', 'D_64_1_first', 'D_64_1_last', 'D_64_1_nunique', 'D_64_2_first', 'D_64_2_last', 'D_64_2_nunique', 'D_64_3_first', 'D_64_3_last', 'D_64_3_nunique', 'D_64_4_last', 'D_66_0_first', 'D_66_0_last', 'D_66_0_nunique', 'D_66_1_first', 'D_66_1_nunique', 'D_66_2_first', 'D_66_2_nunique', 'D_68_0_first', 'D_68_0_last', 'D_68_1_first', 'D_68_1_last', 'D_68_1_nunique', 'D_68_2_first', 'D_68_2_last', 'D_68_2_nunique', 'D_68_3_first', 'D_68_3_last', 'D_68_3_nunique', 'D_68_4_first', 'D_68_4_last', 'D_68_4_nunique', 'D_68_5_first', 'D_68_5_last', 'D_68_5_nunique', 'D_68_6_first', 'D_68_6_last', 'D_68_6_nunique']\n",
    "print(\"number of selected features: \",len(selected_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "41f23547",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T13:41:52.695730Z",
     "iopub.status.busy": "2024-05-13T13:41:52.695348Z",
     "iopub.status.idle": "2024-05-13T13:41:55.753206Z",
     "shell.execute_reply": "2024-05-13T13:41:55.752210Z"
    },
    "papermill": {
     "duration": 3.079988,
     "end_time": "2024-05-13T13:41:55.755842",
     "exception": false,
     "start_time": "2024-05-13T13:41:52.675854",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "x= agg_train[selected_columns]\n",
    "y= agg_train['target']\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "# split data train 70 % and test 30 %\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf91f4fb",
   "metadata": {
    "papermill": {
     "duration": 0.017208,
     "end_time": "2024-05-13T13:41:55.790914",
     "exception": false,
     "start_time": "2024-05-13T13:41:55.773706",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**2.1/ Recursive Feature Elimination using Cross Validation (RFEcv)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ea67af",
   "metadata": {
    "papermill": {
     "duration": 0.016928,
     "end_time": "2024-05-13T13:41:55.825332",
     "exception": false,
     "start_time": "2024-05-13T13:41:55.808404",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c2223a11",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T13:41:55.862576Z",
     "iopub.status.busy": "2024-05-13T13:41:55.862165Z",
     "iopub.status.idle": "2024-05-13T19:01:46.360941Z",
     "shell.execute_reply": "2024-05-13T19:01:46.357048Z"
    },
    "papermill": {
     "duration": 19190.599804,
     "end_time": "2024-05-13T19:01:46.443037",
     "exception": false,
     "start_time": "2024-05-13T13:41:55.843233",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 720 features.\n",
      "[LightGBM] [Info] Number of positive: 65662, number of negative: 188462\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.955671 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 93238\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 700\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258386 -> initscore=-1.054376\n",
      "[LightGBM] [Info] Start training from score -1.054376\n",
      "Fitting estimator with 700 features.\n",
      "[LightGBM] [Info] Number of positive: 65662, number of negative: 188462\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 2.001023 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 92994\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 683\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258386 -> initscore=-1.054376\n",
      "[LightGBM] [Info] Start training from score -1.054376\n",
      "Fitting estimator with 680 features.\n",
      "[LightGBM] [Info] Number of positive: 65662, number of negative: 188462\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.937697 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 91864\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 663\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258386 -> initscore=-1.054376\n",
      "[LightGBM] [Info] Start training from score -1.054376\n",
      "Fitting estimator with 660 features.\n",
      "[LightGBM] [Info] Number of positive: 65662, number of negative: 188462\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.644122 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 89215\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 643\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258386 -> initscore=-1.054376\n",
      "[LightGBM] [Info] Start training from score -1.054376\n",
      "Fitting estimator with 640 features.\n",
      "[LightGBM] [Info] Number of positive: 65662, number of negative: 188462\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.770296 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 88010\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 625\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258386 -> initscore=-1.054376\n",
      "[LightGBM] [Info] Start training from score -1.054376\n",
      "Fitting estimator with 620 features.\n",
      "[LightGBM] [Info] Number of positive: 65662, number of negative: 188462\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.765830 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 87650\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 606\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258386 -> initscore=-1.054376\n",
      "[LightGBM] [Info] Start training from score -1.054376\n",
      "Fitting estimator with 600 features.\n",
      "[LightGBM] [Info] Number of positive: 65662, number of negative: 188462\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.520860 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 85708\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 586\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258386 -> initscore=-1.054376\n",
      "[LightGBM] [Info] Start training from score -1.054376\n",
      "Fitting estimator with 580 features.\n",
      "[LightGBM] [Info] Number of positive: 65662, number of negative: 188462\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.580797 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 84546\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 566\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258386 -> initscore=-1.054376\n",
      "[LightGBM] [Info] Start training from score -1.054376\n",
      "Fitting estimator with 560 features.\n",
      "[LightGBM] [Info] Number of positive: 65662, number of negative: 188462\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.422407 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 82600\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 547\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258386 -> initscore=-1.054376\n",
      "[LightGBM] [Info] Start training from score -1.054376\n",
      "Fitting estimator with 540 features.\n",
      "[LightGBM] [Info] Number of positive: 65662, number of negative: 188462\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.441575 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 80753\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 527\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258386 -> initscore=-1.054376\n",
      "[LightGBM] [Info] Start training from score -1.054376\n",
      "Fitting estimator with 520 features.\n",
      "[LightGBM] [Info] Number of positive: 65662, number of negative: 188462\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.414372 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 79193\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 508\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258386 -> initscore=-1.054376\n",
      "[LightGBM] [Info] Start training from score -1.054376\n",
      "Fitting estimator with 500 features.\n",
      "[LightGBM] [Info] Number of positive: 65662, number of negative: 188462\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.417749 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 78924\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 489\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258386 -> initscore=-1.054376\n",
      "[LightGBM] [Info] Start training from score -1.054376\n",
      "Fitting estimator with 480 features.\n",
      "[LightGBM] [Info] Number of positive: 65662, number of negative: 188462\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.286766 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 76465\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 469\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258386 -> initscore=-1.054376\n",
      "[LightGBM] [Info] Start training from score -1.054376\n",
      "Fitting estimator with 460 features.\n",
      "[LightGBM] [Info] Number of positive: 65662, number of negative: 188462\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.333346 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 75911\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 449\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258386 -> initscore=-1.054376\n",
      "[LightGBM] [Info] Start training from score -1.054376\n",
      "Fitting estimator with 440 features.\n",
      "[LightGBM] [Info] Number of positive: 65662, number of negative: 188462\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.163543 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 74264\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 429\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258386 -> initscore=-1.054376\n",
      "[LightGBM] [Info] Start training from score -1.054376\n",
      "Fitting estimator with 420 features.\n",
      "[LightGBM] [Info] Number of positive: 65662, number of negative: 188462\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.102620 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 72117\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 410\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258386 -> initscore=-1.054376\n",
      "[LightGBM] [Info] Start training from score -1.054376\n",
      "Fitting estimator with 400 features.\n",
      "[LightGBM] [Info] Number of positive: 65662, number of negative: 188462\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.124737 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 70479\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 393\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258386 -> initscore=-1.054376\n",
      "[LightGBM] [Info] Start training from score -1.054376\n",
      "Fitting estimator with 380 features.\n",
      "[LightGBM] [Info] Number of positive: 65662, number of negative: 188462\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.996720 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 68421\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 374\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258386 -> initscore=-1.054376\n",
      "[LightGBM] [Info] Start training from score -1.054376\n",
      "Fitting estimator with 360 features.\n",
      "[LightGBM] [Info] Number of positive: 65662, number of negative: 188462\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.914709 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 65532\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 355\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258386 -> initscore=-1.054376\n",
      "[LightGBM] [Info] Start training from score -1.054376\n",
      "Fitting estimator with 340 features.\n",
      "[LightGBM] [Info] Number of positive: 65662, number of negative: 188462\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.863030 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 63423\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 335\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258386 -> initscore=-1.054376\n",
      "[LightGBM] [Info] Start training from score -1.054376\n",
      "Fitting estimator with 320 features.\n",
      "[LightGBM] [Info] Number of positive: 65662, number of negative: 188462\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.882122 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 61277\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 316\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258386 -> initscore=-1.054376\n",
      "[LightGBM] [Info] Start training from score -1.054376\n",
      "Fitting estimator with 300 features.\n",
      "[LightGBM] [Info] Number of positive: 65662, number of negative: 188462\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.816520 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 59976\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 297\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258386 -> initscore=-1.054376\n",
      "[LightGBM] [Info] Start training from score -1.054376\n",
      "Fitting estimator with 280 features.\n",
      "[LightGBM] [Info] Number of positive: 65662, number of negative: 188462\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.773894 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 57820\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 279\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258386 -> initscore=-1.054376\n",
      "[LightGBM] [Info] Start training from score -1.054376\n",
      "Fitting estimator with 260 features.\n",
      "[LightGBM] [Info] Number of positive: 65662, number of negative: 188462\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.710262 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 54298\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 260\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258386 -> initscore=-1.054376\n",
      "[LightGBM] [Info] Start training from score -1.054376\n",
      "Fitting estimator with 240 features.\n",
      "[LightGBM] [Info] Number of positive: 65662, number of negative: 188462\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.655018 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 50165\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 240\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258386 -> initscore=-1.054376\n",
      "[LightGBM] [Info] Start training from score -1.054376\n",
      "Fitting estimator with 220 features.\n",
      "[LightGBM] [Info] Number of positive: 65662, number of negative: 188462\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.600255 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 45966\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 220\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258386 -> initscore=-1.054376\n",
      "[LightGBM] [Info] Start training from score -1.054376\n",
      "Fitting estimator with 200 features.\n",
      "[LightGBM] [Info] Number of positive: 65662, number of negative: 188462\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.556094 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 43109\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 200\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258386 -> initscore=-1.054376\n",
      "[LightGBM] [Info] Start training from score -1.054376\n",
      "Fitting estimator with 180 features.\n",
      "[LightGBM] [Info] Number of positive: 65662, number of negative: 188462\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 1.128799 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 38573\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 180\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258386 -> initscore=-1.054376\n",
      "[LightGBM] [Info] Start training from score -1.054376\n",
      "Fitting estimator with 160 features.\n",
      "[LightGBM] [Info] Number of positive: 65662, number of negative: 188462\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 1.076918 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34242\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 160\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258386 -> initscore=-1.054376\n",
      "[LightGBM] [Info] Start training from score -1.054376\n",
      "Fitting estimator with 140 features.\n",
      "[LightGBM] [Info] Number of positive: 65662, number of negative: 188462\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.860217 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 30833\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 140\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258386 -> initscore=-1.054376\n",
      "[LightGBM] [Info] Start training from score -1.054376\n",
      "Fitting estimator with 120 features.\n",
      "[LightGBM] [Info] Number of positive: 65662, number of negative: 188462\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.731271 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26977\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 120\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258386 -> initscore=-1.054376\n",
      "[LightGBM] [Info] Start training from score -1.054376\n",
      "Fitting estimator with 100 features.\n",
      "[LightGBM] [Info] Number of positive: 65662, number of negative: 188462\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.595967 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23322\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258386 -> initscore=-1.054376\n",
      "[LightGBM] [Info] Start training from score -1.054376\n",
      "Fitting estimator with 80 features.\n",
      "[LightGBM] [Info] Number of positive: 65662, number of negative: 188462\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.505618 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18723\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 80\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258386 -> initscore=-1.054376\n",
      "[LightGBM] [Info] Start training from score -1.054376\n",
      "Fitting estimator with 60 features.\n",
      "[LightGBM] [Info] Number of positive: 65662, number of negative: 188462\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.353135 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 14298\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 60\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258386 -> initscore=-1.054376\n",
      "[LightGBM] [Info] Start training from score -1.054376\n",
      "Fitting estimator with 40 features.\n",
      "[LightGBM] [Info] Number of positive: 65662, number of negative: 188462\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.237003 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9489\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258386 -> initscore=-1.054376\n",
      "[LightGBM] [Info] Start training from score -1.054376\n",
      "Fitting estimator with 20 features.\n",
      "[LightGBM] [Info] Number of positive: 65662, number of negative: 188462\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.120405 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4876\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258386 -> initscore=-1.054376\n",
      "[LightGBM] [Info] Start training from score -1.054376\n",
      "[LightGBM] [Info] Number of positive: 65662, number of negative: 188462\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005595 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 1\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258386 -> initscore=-1.054376\n",
      "[LightGBM] [Info] Start training from score -1.054376\n",
      "Fitting estimator with 720 features.\n",
      "[LightGBM] [Info] Number of positive: 65527, number of negative: 188597\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 2.032885 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 93231\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 699\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257854 -> initscore=-1.057150\n",
      "[LightGBM] [Info] Start training from score -1.057150\n",
      "Fitting estimator with 700 features.\n",
      "[LightGBM] [Info] Number of positive: 65527, number of negative: 188597\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.808082 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 92686\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 684\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257854 -> initscore=-1.057150\n",
      "[LightGBM] [Info] Start training from score -1.057150\n",
      "Fitting estimator with 680 features.\n",
      "[LightGBM] [Info] Number of positive: 65527, number of negative: 188597\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.910456 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 91787\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 666\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257854 -> initscore=-1.057150\n",
      "[LightGBM] [Info] Start training from score -1.057150\n",
      "Fitting estimator with 660 features.\n",
      "[LightGBM] [Info] Number of positive: 65527, number of negative: 188597\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.844948 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 88170\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 646\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257854 -> initscore=-1.057150\n",
      "[LightGBM] [Info] Start training from score -1.057150\n",
      "Fitting estimator with 640 features.\n",
      "[LightGBM] [Info] Number of positive: 65527, number of negative: 188597\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.646773 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 87597\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 626\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257854 -> initscore=-1.057150\n",
      "[LightGBM] [Info] Start training from score -1.057150\n",
      "Fitting estimator with 620 features.\n",
      "[LightGBM] [Info] Number of positive: 65527, number of negative: 188597\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.713395 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 85270\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 606\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257854 -> initscore=-1.057150\n",
      "[LightGBM] [Info] Start training from score -1.057150\n",
      "Fitting estimator with 600 features.\n",
      "[LightGBM] [Info] Number of positive: 65527, number of negative: 188597\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.630268 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 82656\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 587\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257854 -> initscore=-1.057150\n",
      "[LightGBM] [Info] Start training from score -1.057150\n",
      "Fitting estimator with 580 features.\n",
      "[LightGBM] [Info] Number of positive: 65527, number of negative: 188597\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.612419 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 81001\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 567\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257854 -> initscore=-1.057150\n",
      "[LightGBM] [Info] Start training from score -1.057150\n",
      "Fitting estimator with 560 features.\n",
      "[LightGBM] [Info] Number of positive: 65527, number of negative: 188597\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.506197 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 79490\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 548\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257854 -> initscore=-1.057150\n",
      "[LightGBM] [Info] Start training from score -1.057150\n",
      "Fitting estimator with 540 features.\n",
      "[LightGBM] [Info] Number of positive: 65527, number of negative: 188597\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.454911 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 77506\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 528\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257854 -> initscore=-1.057150\n",
      "[LightGBM] [Info] Start training from score -1.057150\n",
      "Fitting estimator with 520 features.\n",
      "[LightGBM] [Info] Number of positive: 65527, number of negative: 188597\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.428872 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 76063\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 510\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257854 -> initscore=-1.057150\n",
      "[LightGBM] [Info] Start training from score -1.057150\n",
      "Fitting estimator with 500 features.\n",
      "[LightGBM] [Info] Number of positive: 65527, number of negative: 188597\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.252592 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 73700\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 491\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257854 -> initscore=-1.057150\n",
      "[LightGBM] [Info] Start training from score -1.057150\n",
      "Fitting estimator with 480 features.\n",
      "[LightGBM] [Info] Number of positive: 65527, number of negative: 188597\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.301096 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 73307\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 472\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257854 -> initscore=-1.057150\n",
      "[LightGBM] [Info] Start training from score -1.057150\n",
      "Fitting estimator with 460 features.\n",
      "[LightGBM] [Info] Number of positive: 65527, number of negative: 188597\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.143859 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 71020\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 452\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257854 -> initscore=-1.057150\n",
      "[LightGBM] [Info] Start training from score -1.057150\n",
      "Fitting estimator with 440 features.\n",
      "[LightGBM] [Info] Number of positive: 65527, number of negative: 188597\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.207260 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 70446\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 432\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257854 -> initscore=-1.057150\n",
      "[LightGBM] [Info] Start training from score -1.057150\n",
      "Fitting estimator with 420 features.\n",
      "[LightGBM] [Info] Number of positive: 65527, number of negative: 188597\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.142382 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 69070\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 413\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257854 -> initscore=-1.057150\n",
      "[LightGBM] [Info] Start training from score -1.057150\n",
      "Fitting estimator with 400 features.\n",
      "[LightGBM] [Info] Number of positive: 65527, number of negative: 188597\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.006686 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 68966\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 393\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257854 -> initscore=-1.057150\n",
      "[LightGBM] [Info] Start training from score -1.057150\n",
      "Fitting estimator with 380 features.\n",
      "[LightGBM] [Info] Number of positive: 65527, number of negative: 188597\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.959397 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 67155\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 375\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257854 -> initscore=-1.057150\n",
      "[LightGBM] [Info] Start training from score -1.057150\n",
      "Fitting estimator with 360 features.\n",
      "[LightGBM] [Info] Number of positive: 65527, number of negative: 188597\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.919078 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 65145\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 356\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257854 -> initscore=-1.057150\n",
      "[LightGBM] [Info] Start training from score -1.057150\n",
      "Fitting estimator with 340 features.\n",
      "[LightGBM] [Info] Number of positive: 65527, number of negative: 188597\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.867955 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 64332\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 337\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257854 -> initscore=-1.057150\n",
      "[LightGBM] [Info] Start training from score -1.057150\n",
      "Fitting estimator with 320 features.\n",
      "[LightGBM] [Info] Number of positive: 65527, number of negative: 188597\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.819358 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 63721\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 318\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257854 -> initscore=-1.057150\n",
      "[LightGBM] [Info] Start training from score -1.057150\n",
      "Fitting estimator with 300 features.\n",
      "[LightGBM] [Info] Number of positive: 65527, number of negative: 188597\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.785749 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 61094\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 300\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257854 -> initscore=-1.057150\n",
      "[LightGBM] [Info] Start training from score -1.057150\n",
      "Fitting estimator with 280 features.\n",
      "[LightGBM] [Info] Number of positive: 65527, number of negative: 188597\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.741339 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 57588\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 280\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257854 -> initscore=-1.057150\n",
      "[LightGBM] [Info] Start training from score -1.057150\n",
      "Fitting estimator with 260 features.\n",
      "[LightGBM] [Info] Number of positive: 65527, number of negative: 188597\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.689953 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 54118\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 260\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257854 -> initscore=-1.057150\n",
      "[LightGBM] [Info] Start training from score -1.057150\n",
      "Fitting estimator with 240 features.\n",
      "[LightGBM] [Info] Number of positive: 65527, number of negative: 188597\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.635272 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 50771\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 240\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257854 -> initscore=-1.057150\n",
      "[LightGBM] [Info] Start training from score -1.057150\n",
      "Fitting estimator with 220 features.\n",
      "[LightGBM] [Info] Number of positive: 65527, number of negative: 188597\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 1.438040 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 46803\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 220\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257854 -> initscore=-1.057150\n",
      "[LightGBM] [Info] Start training from score -1.057150\n",
      "Fitting estimator with 200 features.\n",
      "[LightGBM] [Info] Number of positive: 65527, number of negative: 188597\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 1.265566 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 42449\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 200\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257854 -> initscore=-1.057150\n",
      "[LightGBM] [Info] Start training from score -1.057150\n",
      "Fitting estimator with 180 features.\n",
      "[LightGBM] [Info] Number of positive: 65527, number of negative: 188597\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.989035 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 39025\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 180\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257854 -> initscore=-1.057150\n",
      "[LightGBM] [Info] Start training from score -1.057150\n",
      "Fitting estimator with 160 features.\n",
      "[LightGBM] [Info] Number of positive: 65527, number of negative: 188597\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 1.034086 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34684\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 160\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257854 -> initscore=-1.057150\n",
      "[LightGBM] [Info] Start training from score -1.057150\n",
      "Fitting estimator with 140 features.\n",
      "[LightGBM] [Info] Number of positive: 65527, number of negative: 188597\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.894820 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 30842\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 140\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257854 -> initscore=-1.057150\n",
      "[LightGBM] [Info] Start training from score -1.057150\n",
      "Fitting estimator with 120 features.\n",
      "[LightGBM] [Info] Number of positive: 65527, number of negative: 188597\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.777635 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26960\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 120\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257854 -> initscore=-1.057150\n",
      "[LightGBM] [Info] Start training from score -1.057150\n",
      "Fitting estimator with 100 features.\n",
      "[LightGBM] [Info] Number of positive: 65527, number of negative: 188597\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.631988 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 22299\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257854 -> initscore=-1.057150\n",
      "[LightGBM] [Info] Start training from score -1.057150\n",
      "Fitting estimator with 80 features.\n",
      "[LightGBM] [Info] Number of positive: 65527, number of negative: 188597\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.483814 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18531\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 80\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257854 -> initscore=-1.057150\n",
      "[LightGBM] [Info] Start training from score -1.057150\n",
      "Fitting estimator with 60 features.\n",
      "[LightGBM] [Info] Number of positive: 65527, number of negative: 188597\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.362936 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 14079\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 60\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257854 -> initscore=-1.057150\n",
      "[LightGBM] [Info] Start training from score -1.057150\n",
      "Fitting estimator with 40 features.\n",
      "[LightGBM] [Info] Number of positive: 65527, number of negative: 188597\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.237075 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9700\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257854 -> initscore=-1.057150\n",
      "[LightGBM] [Info] Start training from score -1.057150\n",
      "Fitting estimator with 20 features.\n",
      "[LightGBM] [Info] Number of positive: 65527, number of negative: 188597\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.124271 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4879\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257854 -> initscore=-1.057150\n",
      "[LightGBM] [Info] Start training from score -1.057150\n",
      "[LightGBM] [Info] Number of positive: 65527, number of negative: 188597\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005564 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 1\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257854 -> initscore=-1.057150\n",
      "[LightGBM] [Info] Start training from score -1.057150\n",
      "Fitting estimator with 720 features.\n",
      "[LightGBM] [Info] Number of positive: 65481, number of negative: 188643\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.973141 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 93246\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 700\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257673 -> initscore=-1.058096\n",
      "[LightGBM] [Info] Start training from score -1.058096\n",
      "Fitting estimator with 700 features.\n",
      "[LightGBM] [Info] Number of positive: 65481, number of negative: 188643\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.965593 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 92303\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 681\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257673 -> initscore=-1.058096\n",
      "[LightGBM] [Info] Start training from score -1.058096\n",
      "Fitting estimator with 680 features.\n",
      "[LightGBM] [Info] Number of positive: 65481, number of negative: 188643\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.743747 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 89614\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 662\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257673 -> initscore=-1.058096\n",
      "[LightGBM] [Info] Start training from score -1.058096\n",
      "Fitting estimator with 660 features.\n",
      "[LightGBM] [Info] Number of positive: 65481, number of negative: 188643\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.866929 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 89233\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 646\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257673 -> initscore=-1.058096\n",
      "[LightGBM] [Info] Start training from score -1.058096\n",
      "Fitting estimator with 640 features.\n",
      "[LightGBM] [Info] Number of positive: 65481, number of negative: 188643\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.791233 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 88314\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 628\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257673 -> initscore=-1.058096\n",
      "[LightGBM] [Info] Start training from score -1.058096\n",
      "Fitting estimator with 620 features.\n",
      "[LightGBM] [Info] Number of positive: 65481, number of negative: 188643\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.789546 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 87819\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 610\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257673 -> initscore=-1.058096\n",
      "[LightGBM] [Info] Start training from score -1.058096\n",
      "Fitting estimator with 600 features.\n",
      "[LightGBM] [Info] Number of positive: 65481, number of negative: 188643\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.740795 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 86703\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 591\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257673 -> initscore=-1.058096\n",
      "[LightGBM] [Info] Start training from score -1.058096\n",
      "Fitting estimator with 580 features.\n",
      "[LightGBM] [Info] Number of positive: 65481, number of negative: 188643\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.516088 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 85428\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 571\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257673 -> initscore=-1.058096\n",
      "[LightGBM] [Info] Start training from score -1.058096\n",
      "Fitting estimator with 560 features.\n",
      "[LightGBM] [Info] Number of positive: 65481, number of negative: 188643\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.582885 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 84303\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 551\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257673 -> initscore=-1.058096\n",
      "[LightGBM] [Info] Start training from score -1.058096\n",
      "Fitting estimator with 540 features.\n",
      "[LightGBM] [Info] Number of positive: 65481, number of negative: 188643\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.399755 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 83373\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 532\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257673 -> initscore=-1.058096\n",
      "[LightGBM] [Info] Start training from score -1.058096\n",
      "Fitting estimator with 520 features.\n",
      "[LightGBM] [Info] Number of positive: 65481, number of negative: 188643\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.468029 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 81597\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 513\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257673 -> initscore=-1.058096\n",
      "[LightGBM] [Info] Start training from score -1.058096\n",
      "Fitting estimator with 500 features.\n",
      "[LightGBM] [Info] Number of positive: 65481, number of negative: 188643\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.433906 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 79777\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 493\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257673 -> initscore=-1.058096\n",
      "[LightGBM] [Info] Start training from score -1.058096\n",
      "Fitting estimator with 480 features.\n",
      "[LightGBM] [Info] Number of positive: 65481, number of negative: 188643\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.215867 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 78353\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257673 -> initscore=-1.058096\n",
      "[LightGBM] [Info] Start training from score -1.058096\n",
      "Fitting estimator with 460 features.\n",
      "[LightGBM] [Info] Number of positive: 65481, number of negative: 188643\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.302608 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 75669\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 454\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257673 -> initscore=-1.058096\n",
      "[LightGBM] [Info] Start training from score -1.058096\n",
      "Fitting estimator with 440 features.\n",
      "[LightGBM] [Info] Number of positive: 65481, number of negative: 188643\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.249619 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 74087\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 435\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257673 -> initscore=-1.058096\n",
      "[LightGBM] [Info] Start training from score -1.058096\n",
      "Fitting estimator with 420 features.\n",
      "[LightGBM] [Info] Number of positive: 65481, number of negative: 188643\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.192671 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 72867\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 415\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257673 -> initscore=-1.058096\n",
      "[LightGBM] [Info] Start training from score -1.058096\n",
      "Fitting estimator with 400 features.\n",
      "[LightGBM] [Info] Number of positive: 65481, number of negative: 188643\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.121618 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 71836\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 395\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257673 -> initscore=-1.058096\n",
      "[LightGBM] [Info] Start training from score -1.058096\n",
      "Fitting estimator with 380 features.\n",
      "[LightGBM] [Info] Number of positive: 65481, number of negative: 188643\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.094486 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 69287\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 375\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257673 -> initscore=-1.058096\n",
      "[LightGBM] [Info] Start training from score -1.058096\n",
      "Fitting estimator with 360 features.\n",
      "[LightGBM] [Info] Number of positive: 65481, number of negative: 188643\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.003104 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 67425\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 357\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257673 -> initscore=-1.058096\n",
      "[LightGBM] [Info] Start training from score -1.058096\n",
      "Fitting estimator with 340 features.\n",
      "[LightGBM] [Info] Number of positive: 65481, number of negative: 188643\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.962454 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 65878\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 338\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257673 -> initscore=-1.058096\n",
      "[LightGBM] [Info] Start training from score -1.058096\n",
      "Fitting estimator with 320 features.\n",
      "[LightGBM] [Info] Number of positive: 65481, number of negative: 188643\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.930889 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 64506\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 320\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257673 -> initscore=-1.058096\n",
      "[LightGBM] [Info] Start training from score -1.058096\n",
      "Fitting estimator with 300 features.\n",
      "[LightGBM] [Info] Number of positive: 65481, number of negative: 188643\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.868256 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 61325\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 300\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257673 -> initscore=-1.058096\n",
      "[LightGBM] [Info] Start training from score -1.058096\n",
      "Fitting estimator with 280 features.\n",
      "[LightGBM] [Info] Number of positive: 65481, number of negative: 188643\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.798168 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 57549\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 280\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257673 -> initscore=-1.058096\n",
      "[LightGBM] [Info] Start training from score -1.058096\n",
      "Fitting estimator with 260 features.\n",
      "[LightGBM] [Info] Number of positive: 65481, number of negative: 188643\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.753426 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 53656\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 260\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257673 -> initscore=-1.058096\n",
      "[LightGBM] [Info] Start training from score -1.058096\n",
      "Fitting estimator with 240 features.\n",
      "[LightGBM] [Info] Number of positive: 65481, number of negative: 188643\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.693034 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 49795\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 240\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257673 -> initscore=-1.058096\n",
      "[LightGBM] [Info] Start training from score -1.058096\n",
      "Fitting estimator with 220 features.\n",
      "[LightGBM] [Info] Number of positive: 65481, number of negative: 188643\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.618931 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 46217\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 220\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257673 -> initscore=-1.058096\n",
      "[LightGBM] [Info] Start training from score -1.058096\n",
      "Fitting estimator with 200 features.\n",
      "[LightGBM] [Info] Number of positive: 65481, number of negative: 188643\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 1.269543 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 43116\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 200\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257673 -> initscore=-1.058096\n",
      "[LightGBM] [Info] Start training from score -1.058096\n",
      "Fitting estimator with 180 features.\n",
      "[LightGBM] [Info] Number of positive: 65481, number of negative: 188643\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 1.139043 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 39214\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 180\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257673 -> initscore=-1.058096\n",
      "[LightGBM] [Info] Start training from score -1.058096\n",
      "Fitting estimator with 160 features.\n",
      "[LightGBM] [Info] Number of positive: 65481, number of negative: 188643\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 2.230970 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 35633\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 160\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257673 -> initscore=-1.058096\n",
      "[LightGBM] [Info] Start training from score -1.058096\n",
      "Fitting estimator with 140 features.\n",
      "[LightGBM] [Info] Number of positive: 65481, number of negative: 188643\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.889825 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 30609\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 140\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257673 -> initscore=-1.058096\n",
      "[LightGBM] [Info] Start training from score -1.058096\n",
      "Fitting estimator with 120 features.\n",
      "[LightGBM] [Info] Number of positive: 65481, number of negative: 188643\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.753598 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26980\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 120\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257673 -> initscore=-1.058096\n",
      "[LightGBM] [Info] Start training from score -1.058096\n",
      "Fitting estimator with 100 features.\n",
      "[LightGBM] [Info] Number of positive: 65481, number of negative: 188643\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.616568 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23494\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257673 -> initscore=-1.058096\n",
      "[LightGBM] [Info] Start training from score -1.058096\n",
      "Fitting estimator with 80 features.\n",
      "[LightGBM] [Info] Number of positive: 65481, number of negative: 188643\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.475855 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19136\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 80\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257673 -> initscore=-1.058096\n",
      "[LightGBM] [Info] Start training from score -1.058096\n",
      "Fitting estimator with 60 features.\n",
      "[LightGBM] [Info] Number of positive: 65481, number of negative: 188643\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.356886 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 14154\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 60\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257673 -> initscore=-1.058096\n",
      "[LightGBM] [Info] Start training from score -1.058096\n",
      "Fitting estimator with 40 features.\n",
      "[LightGBM] [Info] Number of positive: 65481, number of negative: 188643\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.235896 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9748\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257673 -> initscore=-1.058096\n",
      "[LightGBM] [Info] Start training from score -1.058096\n",
      "Fitting estimator with 20 features.\n",
      "[LightGBM] [Info] Number of positive: 65481, number of negative: 188643\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.124011 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4878\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257673 -> initscore=-1.058096\n",
      "[LightGBM] [Info] Start training from score -1.058096\n",
      "[LightGBM] [Info] Number of positive: 65481, number of negative: 188643\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005689 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 1\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257673 -> initscore=-1.058096\n",
      "[LightGBM] [Info] Start training from score -1.058096\n",
      "Fitting estimator with 720 features.\n",
      "[LightGBM] [Info] Number of positive: 65759, number of negative: 188365\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 2.005725 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 93249\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 700\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258767 -> initscore=-1.052385\n",
      "[LightGBM] [Info] Start training from score -1.052385\n",
      "Fitting estimator with 700 features.\n",
      "[LightGBM] [Info] Number of positive: 65759, number of negative: 188365\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.782944 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 92932\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 681\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258767 -> initscore=-1.052385\n",
      "[LightGBM] [Info] Start training from score -1.052385\n",
      "Fitting estimator with 680 features.\n",
      "[LightGBM] [Info] Number of positive: 65759, number of negative: 188365\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.934572 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 91457\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 662\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258767 -> initscore=-1.052385\n",
      "[LightGBM] [Info] Start training from score -1.052385\n",
      "Fitting estimator with 660 features.\n",
      "[LightGBM] [Info] Number of positive: 65759, number of negative: 188365\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.682666 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 90453\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 646\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258767 -> initscore=-1.052385\n",
      "[LightGBM] [Info] Start training from score -1.052385\n",
      "Fitting estimator with 640 features.\n",
      "[LightGBM] [Info] Number of positive: 65759, number of negative: 188365\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.776880 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 88030\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 627\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258767 -> initscore=-1.052385\n",
      "[LightGBM] [Info] Start training from score -1.052385\n",
      "Fitting estimator with 620 features.\n",
      "[LightGBM] [Info] Number of positive: 65759, number of negative: 188365\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.744551 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 87709\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 609\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258767 -> initscore=-1.052385\n",
      "[LightGBM] [Info] Start training from score -1.052385\n",
      "Fitting estimator with 600 features.\n",
      "[LightGBM] [Info] Number of positive: 65759, number of negative: 188365\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.726081 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 87326\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 592\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258767 -> initscore=-1.052385\n",
      "[LightGBM] [Info] Start training from score -1.052385\n",
      "Fitting estimator with 580 features.\n",
      "[LightGBM] [Info] Number of positive: 65759, number of negative: 188365\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.672229 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 85243\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 572\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258767 -> initscore=-1.052385\n",
      "[LightGBM] [Info] Start training from score -1.052385\n",
      "Fitting estimator with 560 features.\n",
      "[LightGBM] [Info] Number of positive: 65759, number of negative: 188365\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.420061 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 82814\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 552\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258767 -> initscore=-1.052385\n",
      "[LightGBM] [Info] Start training from score -1.052385\n",
      "Fitting estimator with 540 features.\n",
      "[LightGBM] [Info] Number of positive: 65759, number of negative: 188365\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.553218 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 81721\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 533\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258767 -> initscore=-1.052385\n",
      "[LightGBM] [Info] Start training from score -1.052385\n",
      "Fitting estimator with 520 features.\n",
      "[LightGBM] [Info] Number of positive: 65759, number of negative: 188365\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.432802 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 79345\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 513\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258767 -> initscore=-1.052385\n",
      "[LightGBM] [Info] Start training from score -1.052385\n",
      "Fitting estimator with 500 features.\n",
      "[LightGBM] [Info] Number of positive: 65759, number of negative: 188365\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.369545 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 77445\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 493\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258767 -> initscore=-1.052385\n",
      "[LightGBM] [Info] Start training from score -1.052385\n",
      "Fitting estimator with 480 features.\n",
      "[LightGBM] [Info] Number of positive: 65759, number of negative: 188365\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.292998 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 76757\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 473\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258767 -> initscore=-1.052385\n",
      "[LightGBM] [Info] Start training from score -1.052385\n",
      "Fitting estimator with 460 features.\n",
      "[LightGBM] [Info] Number of positive: 65759, number of negative: 188365\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.256798 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 74854\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 453\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258767 -> initscore=-1.052385\n",
      "[LightGBM] [Info] Start training from score -1.052385\n",
      "Fitting estimator with 440 features.\n",
      "[LightGBM] [Info] Number of positive: 65759, number of negative: 188365\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.180085 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 72914\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 433\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258767 -> initscore=-1.052385\n",
      "[LightGBM] [Info] Start training from score -1.052385\n",
      "Fitting estimator with 420 features.\n",
      "[LightGBM] [Info] Number of positive: 65759, number of negative: 188365\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.130045 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 72098\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 413\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258767 -> initscore=-1.052385\n",
      "[LightGBM] [Info] Start training from score -1.052385\n",
      "Fitting estimator with 400 features.\n",
      "[LightGBM] [Info] Number of positive: 65759, number of negative: 188365\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.082086 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 70621\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 393\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258767 -> initscore=-1.052385\n",
      "[LightGBM] [Info] Start training from score -1.052385\n",
      "Fitting estimator with 380 features.\n",
      "[LightGBM] [Info] Number of positive: 65759, number of negative: 188365\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.068574 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 69105\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 374\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258767 -> initscore=-1.052385\n",
      "[LightGBM] [Info] Start training from score -1.052385\n",
      "Fitting estimator with 360 features.\n",
      "[LightGBM] [Info] Number of positive: 65759, number of negative: 188365\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.993325 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 68289\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 356\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258767 -> initscore=-1.052385\n",
      "[LightGBM] [Info] Start training from score -1.052385\n",
      "Fitting estimator with 340 features.\n",
      "[LightGBM] [Info] Number of positive: 65759, number of negative: 188365\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.933469 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 67741\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 338\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258767 -> initscore=-1.052385\n",
      "[LightGBM] [Info] Start training from score -1.052385\n",
      "Fitting estimator with 320 features.\n",
      "[LightGBM] [Info] Number of positive: 65759, number of negative: 188365\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.875629 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 65899\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 320\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258767 -> initscore=-1.052385\n",
      "[LightGBM] [Info] Start training from score -1.052385\n",
      "Fitting estimator with 300 features.\n",
      "[LightGBM] [Info] Number of positive: 65759, number of negative: 188365\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.880151 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 61661\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 300\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258767 -> initscore=-1.052385\n",
      "[LightGBM] [Info] Start training from score -1.052385\n",
      "Fitting estimator with 280 features.\n",
      "[LightGBM] [Info] Number of positive: 65759, number of negative: 188365\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.812889 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 58319\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 280\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258767 -> initscore=-1.052385\n",
      "[LightGBM] [Info] Start training from score -1.052385\n",
      "Fitting estimator with 260 features.\n",
      "[LightGBM] [Info] Number of positive: 65759, number of negative: 188365\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.737874 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 54560\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 260\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258767 -> initscore=-1.052385\n",
      "[LightGBM] [Info] Start training from score -1.052385\n",
      "Fitting estimator with 240 features.\n",
      "[LightGBM] [Info] Number of positive: 65759, number of negative: 188365\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 1.553561 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 50742\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 240\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258767 -> initscore=-1.052385\n",
      "[LightGBM] [Info] Start training from score -1.052385\n",
      "Fitting estimator with 220 features.\n",
      "[LightGBM] [Info] Number of positive: 65759, number of negative: 188365\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.588051 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 47149\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 220\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258767 -> initscore=-1.052385\n",
      "[LightGBM] [Info] Start training from score -1.052385\n",
      "Fitting estimator with 200 features.\n",
      "[LightGBM] [Info] Number of positive: 65759, number of negative: 188365\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 1.267282 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 43590\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 200\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258767 -> initscore=-1.052385\n",
      "[LightGBM] [Info] Start training from score -1.052385\n",
      "Fitting estimator with 180 features.\n",
      "[LightGBM] [Info] Number of positive: 65759, number of negative: 188365\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 1.120015 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 38803\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 180\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258767 -> initscore=-1.052385\n",
      "[LightGBM] [Info] Start training from score -1.052385\n",
      "Fitting estimator with 160 features.\n",
      "[LightGBM] [Info] Number of positive: 65759, number of negative: 188365\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.997670 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34630\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 160\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258767 -> initscore=-1.052385\n",
      "[LightGBM] [Info] Start training from score -1.052385\n",
      "Fitting estimator with 140 features.\n",
      "[LightGBM] [Info] Number of positive: 65759, number of negative: 188365\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.885318 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 30863\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 140\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258767 -> initscore=-1.052385\n",
      "[LightGBM] [Info] Start training from score -1.052385\n",
      "Fitting estimator with 120 features.\n",
      "[LightGBM] [Info] Number of positive: 65759, number of negative: 188365\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.745872 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26767\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 120\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258767 -> initscore=-1.052385\n",
      "[LightGBM] [Info] Start training from score -1.052385\n",
      "Fitting estimator with 100 features.\n",
      "[LightGBM] [Info] Number of positive: 65759, number of negative: 188365\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.637357 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 22570\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258767 -> initscore=-1.052385\n",
      "[LightGBM] [Info] Start training from score -1.052385\n",
      "Fitting estimator with 80 features.\n",
      "[LightGBM] [Info] Number of positive: 65759, number of negative: 188365\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.510238 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18310\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 80\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258767 -> initscore=-1.052385\n",
      "[LightGBM] [Info] Start training from score -1.052385\n",
      "Fitting estimator with 60 features.\n",
      "[LightGBM] [Info] Number of positive: 65759, number of negative: 188365\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.567591 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 14085\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 60\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258767 -> initscore=-1.052385\n",
      "[LightGBM] [Info] Start training from score -1.052385\n",
      "Fitting estimator with 40 features.\n",
      "[LightGBM] [Info] Number of positive: 65759, number of negative: 188365\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.237520 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9810\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258767 -> initscore=-1.052385\n",
      "[LightGBM] [Info] Start training from score -1.052385\n",
      "Fitting estimator with 20 features.\n",
      "[LightGBM] [Info] Number of positive: 65759, number of negative: 188365\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.111210 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4879\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258767 -> initscore=-1.052385\n",
      "[LightGBM] [Info] Start training from score -1.052385\n",
      "[LightGBM] [Info] Number of positive: 65759, number of negative: 188365\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005523 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 1\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258767 -> initscore=-1.052385\n",
      "[LightGBM] [Info] Start training from score -1.052385\n",
      "Fitting estimator with 720 features.\n",
      "[LightGBM] [Info] Number of positive: 65831, number of negative: 188293\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.797655 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 93219\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 700\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.259051 -> initscore=-1.050908\n",
      "[LightGBM] [Info] Start training from score -1.050908\n",
      "Fitting estimator with 700 features.\n",
      "[LightGBM] [Info] Number of positive: 65831, number of negative: 188293\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.993035 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 92641\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 682\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.259051 -> initscore=-1.050908\n",
      "[LightGBM] [Info] Start training from score -1.050908\n",
      "Fitting estimator with 680 features.\n",
      "[LightGBM] [Info] Number of positive: 65831, number of negative: 188293\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.916260 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 91713\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 664\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.259051 -> initscore=-1.050908\n",
      "[LightGBM] [Info] Start training from score -1.050908\n",
      "Fitting estimator with 660 features.\n",
      "[LightGBM] [Info] Number of positive: 65831, number of negative: 188293\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.899250 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 90710\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 645\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.259051 -> initscore=-1.050908\n",
      "[LightGBM] [Info] Start training from score -1.050908\n",
      "Fitting estimator with 640 features.\n",
      "[LightGBM] [Info] Number of positive: 65831, number of negative: 188293\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.623023 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 88685\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 626\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.259051 -> initscore=-1.050908\n",
      "[LightGBM] [Info] Start training from score -1.050908\n",
      "Fitting estimator with 620 features.\n",
      "[LightGBM] [Info] Number of positive: 65831, number of negative: 188293\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.772428 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 87876\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 607\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.259051 -> initscore=-1.050908\n",
      "[LightGBM] [Info] Start training from score -1.050908\n",
      "Fitting estimator with 600 features.\n",
      "[LightGBM] [Info] Number of positive: 65831, number of negative: 188293\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.702073 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 87387\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 589\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.259051 -> initscore=-1.050908\n",
      "[LightGBM] [Info] Start training from score -1.050908\n",
      "Fitting estimator with 580 features.\n",
      "[LightGBM] [Info] Number of positive: 65831, number of negative: 188293\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.487315 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 86187\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 570\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.259051 -> initscore=-1.050908\n",
      "[LightGBM] [Info] Start training from score -1.050908\n",
      "Fitting estimator with 560 features.\n",
      "[LightGBM] [Info] Number of positive: 65831, number of negative: 188293\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.607920 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 85876\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 554\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.259051 -> initscore=-1.050908\n",
      "[LightGBM] [Info] Start training from score -1.050908\n",
      "Fitting estimator with 540 features.\n",
      "[LightGBM] [Info] Number of positive: 65831, number of negative: 188293\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.520853 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 84284\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 535\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.259051 -> initscore=-1.050908\n",
      "[LightGBM] [Info] Start training from score -1.050908\n",
      "Fitting estimator with 520 features.\n",
      "[LightGBM] [Info] Number of positive: 65831, number of negative: 188293\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.470393 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 82131\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 516\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.259051 -> initscore=-1.050908\n",
      "[LightGBM] [Info] Start training from score -1.050908\n",
      "Fitting estimator with 500 features.\n",
      "[LightGBM] [Info] Number of positive: 65831, number of negative: 188293\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.433076 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 80202\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 496\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.259051 -> initscore=-1.050908\n",
      "[LightGBM] [Info] Start training from score -1.050908\n",
      "Fitting estimator with 480 features.\n",
      "[LightGBM] [Info] Number of positive: 65831, number of negative: 188293\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.224035 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 78414\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 476\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.259051 -> initscore=-1.050908\n",
      "[LightGBM] [Info] Start training from score -1.050908\n",
      "Fitting estimator with 460 features.\n",
      "[LightGBM] [Info] Number of positive: 65831, number of negative: 188293\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.255998 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 77704\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 456\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.259051 -> initscore=-1.050908\n",
      "[LightGBM] [Info] Start training from score -1.050908\n",
      "Fitting estimator with 440 features.\n",
      "[LightGBM] [Info] Number of positive: 65831, number of negative: 188293\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.208988 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 76504\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 436\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.259051 -> initscore=-1.050908\n",
      "[LightGBM] [Info] Start training from score -1.050908\n",
      "Fitting estimator with 420 features.\n",
      "[LightGBM] [Info] Number of positive: 65831, number of negative: 188293\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.145400 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 74669\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 416\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.259051 -> initscore=-1.050908\n",
      "[LightGBM] [Info] Start training from score -1.050908\n",
      "Fitting estimator with 400 features.\n",
      "[LightGBM] [Info] Number of positive: 65831, number of negative: 188293\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.079286 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 74280\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 396\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.259051 -> initscore=-1.050908\n",
      "[LightGBM] [Info] Start training from score -1.050908\n",
      "Fitting estimator with 380 features.\n",
      "[LightGBM] [Info] Number of positive: 65831, number of negative: 188293\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.040947 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 73191\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 377\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.259051 -> initscore=-1.050908\n",
      "[LightGBM] [Info] Start training from score -1.050908\n",
      "Fitting estimator with 360 features.\n",
      "[LightGBM] [Info] Number of positive: 65831, number of negative: 188293\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.991610 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 72050\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 358\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.259051 -> initscore=-1.050908\n",
      "[LightGBM] [Info] Start training from score -1.050908\n",
      "Fitting estimator with 340 features.\n",
      "[LightGBM] [Info] Number of positive: 65831, number of negative: 188293\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.008611 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 70639\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 340\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.259051 -> initscore=-1.050908\n",
      "[LightGBM] [Info] Start training from score -1.050908\n",
      "Fitting estimator with 320 features.\n",
      "[LightGBM] [Info] Number of positive: 65831, number of negative: 188293\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.889132 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 66729\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 320\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.259051 -> initscore=-1.050908\n",
      "[LightGBM] [Info] Start training from score -1.050908\n",
      "Fitting estimator with 300 features.\n",
      "[LightGBM] [Info] Number of positive: 65831, number of negative: 188293\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.847462 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 63998\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 300\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.259051 -> initscore=-1.050908\n",
      "[LightGBM] [Info] Start training from score -1.050908\n",
      "Fitting estimator with 280 features.\n",
      "[LightGBM] [Info] Number of positive: 65831, number of negative: 188293\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.810704 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 60312\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 280\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.259051 -> initscore=-1.050908\n",
      "[LightGBM] [Info] Start training from score -1.050908\n",
      "Fitting estimator with 260 features.\n",
      "[LightGBM] [Info] Number of positive: 65831, number of negative: 188293\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.753633 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 55739\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 260\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.259051 -> initscore=-1.050908\n",
      "[LightGBM] [Info] Start training from score -1.050908\n",
      "Fitting estimator with 240 features.\n",
      "[LightGBM] [Info] Number of positive: 65831, number of negative: 188293\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.668924 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 51053\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 240\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.259051 -> initscore=-1.050908\n",
      "[LightGBM] [Info] Start training from score -1.050908\n",
      "Fitting estimator with 220 features.\n",
      "[LightGBM] [Info] Number of positive: 65831, number of negative: 188293\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 1.421568 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 46966\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 220\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.259051 -> initscore=-1.050908\n",
      "[LightGBM] [Info] Start training from score -1.050908\n",
      "Fitting estimator with 200 features.\n",
      "[LightGBM] [Info] Number of positive: 65831, number of negative: 188293\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.530239 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 43017\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 200\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.259051 -> initscore=-1.050908\n",
      "[LightGBM] [Info] Start training from score -1.050908\n",
      "Fitting estimator with 180 features.\n",
      "[LightGBM] [Info] Number of positive: 65831, number of negative: 188293\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.485094 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 38919\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 180\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.259051 -> initscore=-1.050908\n",
      "[LightGBM] [Info] Start training from score -1.050908\n",
      "Fitting estimator with 160 features.\n",
      "[LightGBM] [Info] Number of positive: 65831, number of negative: 188293\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 1.025980 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34924\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 160\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.259051 -> initscore=-1.050908\n",
      "[LightGBM] [Info] Start training from score -1.050908\n",
      "Fitting estimator with 140 features.\n",
      "[LightGBM] [Info] Number of positive: 65831, number of negative: 188293\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.892690 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 31089\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 140\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.259051 -> initscore=-1.050908\n",
      "[LightGBM] [Info] Start training from score -1.050908\n",
      "Fitting estimator with 120 features.\n",
      "[LightGBM] [Info] Number of positive: 65831, number of negative: 188293\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.755855 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26886\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 120\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.259051 -> initscore=-1.050908\n",
      "[LightGBM] [Info] Start training from score -1.050908\n",
      "Fitting estimator with 100 features.\n",
      "[LightGBM] [Info] Number of positive: 65831, number of negative: 188293\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.645267 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 22312\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.259051 -> initscore=-1.050908\n",
      "[LightGBM] [Info] Start training from score -1.050908\n",
      "Fitting estimator with 80 features.\n",
      "[LightGBM] [Info] Number of positive: 65831, number of negative: 188293\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.475820 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18996\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 80\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.259051 -> initscore=-1.050908\n",
      "[LightGBM] [Info] Start training from score -1.050908\n",
      "Fitting estimator with 60 features.\n",
      "[LightGBM] [Info] Number of positive: 65831, number of negative: 188293\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.355132 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 14460\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 60\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.259051 -> initscore=-1.050908\n",
      "[LightGBM] [Info] Start training from score -1.050908\n",
      "Fitting estimator with 40 features.\n",
      "[LightGBM] [Info] Number of positive: 65831, number of negative: 188293\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.233296 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9640\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.259051 -> initscore=-1.050908\n",
      "[LightGBM] [Info] Start training from score -1.050908\n",
      "Fitting estimator with 20 features.\n",
      "[LightGBM] [Info] Number of positive: 65831, number of negative: 188293\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.105069 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4877\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.259051 -> initscore=-1.050908\n",
      "[LightGBM] [Info] Start training from score -1.050908\n",
      "[LightGBM] [Info] Number of positive: 65831, number of negative: 188293\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005674 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 254124, number of used features: 1\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.259051 -> initscore=-1.050908\n",
      "[LightGBM] [Info] Start training from score -1.050908\n",
      "Fitting estimator with 720 features.\n",
      "[LightGBM] [Info] Number of positive: 82065, number of negative: 235590\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 2.513191 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 93244\n",
      "[LightGBM] [Info] Number of data points in the train set: 317655, number of used features: 702\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258346 -> initscore=-1.054581\n",
      "[LightGBM] [Info] Start training from score -1.054581\n",
      "Fitting estimator with 700 features.\n",
      "[LightGBM] [Info] Number of positive: 82065, number of negative: 235590\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 2.208633 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 92197\n",
      "[LightGBM] [Info] Number of data points in the train set: 317655, number of used features: 683\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258346 -> initscore=-1.054581\n",
      "[LightGBM] [Info] Start training from score -1.054581\n",
      "Fitting estimator with 680 features.\n",
      "[LightGBM] [Info] Number of positive: 82065, number of negative: 235590\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 2.353154 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 91880\n",
      "[LightGBM] [Info] Number of data points in the train set: 317655, number of used features: 665\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258346 -> initscore=-1.054581\n",
      "[LightGBM] [Info] Start training from score -1.054581\n",
      "Fitting estimator with 660 features.\n",
      "[LightGBM] [Info] Number of positive: 82065, number of negative: 235590\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 2.382309 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 91375\n",
      "[LightGBM] [Info] Number of data points in the train set: 317655, number of used features: 647\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258346 -> initscore=-1.054581\n",
      "[LightGBM] [Info] Start training from score -1.054581\n",
      "Fitting estimator with 640 features.\n",
      "[LightGBM] [Info] Number of positive: 82065, number of negative: 235590\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 2.245062 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 89601\n",
      "[LightGBM] [Info] Number of data points in the train set: 317655, number of used features: 628\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258346 -> initscore=-1.054581\n",
      "[LightGBM] [Info] Start training from score -1.054581\n",
      "Fitting estimator with 620 features.\n",
      "[LightGBM] [Info] Number of positive: 82065, number of negative: 235590\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 2.168119 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 88806\n",
      "[LightGBM] [Info] Number of data points in the train set: 317655, number of used features: 610\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258346 -> initscore=-1.054581\n",
      "[LightGBM] [Info] Start training from score -1.054581\n",
      "Fitting estimator with 600 features.\n",
      "[LightGBM] [Info] Number of positive: 82065, number of negative: 235590\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 2.169413 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 87805\n",
      "[LightGBM] [Info] Number of data points in the train set: 317655, number of used features: 592\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258346 -> initscore=-1.054581\n",
      "[LightGBM] [Info] Start training from score -1.054581\n",
      "Fitting estimator with 580 features.\n",
      "[LightGBM] [Info] Number of positive: 82065, number of negative: 235590\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 2.158057 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 86190\n",
      "[LightGBM] [Info] Number of data points in the train set: 317655, number of used features: 572\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258346 -> initscore=-1.054581\n",
      "[LightGBM] [Info] Start training from score -1.054581\n",
      "Fitting estimator with 560 features.\n",
      "[LightGBM] [Info] Number of positive: 82065, number of negative: 235590\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.932445 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 84566\n",
      "[LightGBM] [Info] Number of data points in the train set: 317655, number of used features: 552\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258346 -> initscore=-1.054581\n",
      "[LightGBM] [Info] Start training from score -1.054581\n",
      "Fitting estimator with 540 features.\n",
      "[LightGBM] [Info] Number of positive: 82065, number of negative: 235590\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.868243 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 83322\n",
      "[LightGBM] [Info] Number of data points in the train set: 317655, number of used features: 534\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258346 -> initscore=-1.054581\n",
      "[LightGBM] [Info] Start training from score -1.054581\n",
      "Fitting estimator with 520 features.\n",
      "[LightGBM] [Info] Number of positive: 82065, number of negative: 235590\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.780577 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 80768\n",
      "[LightGBM] [Info] Number of data points in the train set: 317655, number of used features: 514\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258346 -> initscore=-1.054581\n",
      "[LightGBM] [Info] Start training from score -1.054581\n",
      "Fitting estimator with 500 features.\n",
      "[LightGBM] [Info] Number of positive: 82065, number of negative: 235590\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.716835 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 79651\n",
      "[LightGBM] [Info] Number of data points in the train set: 317655, number of used features: 494\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258346 -> initscore=-1.054581\n",
      "[LightGBM] [Info] Start training from score -1.054581\n",
      "Fitting estimator with 480 features.\n",
      "[LightGBM] [Info] Number of positive: 82065, number of negative: 235590\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.646986 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 77045\n",
      "[LightGBM] [Info] Number of data points in the train set: 317655, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258346 -> initscore=-1.054581\n",
      "[LightGBM] [Info] Start training from score -1.054581\n",
      "Fitting estimator with 460 features.\n",
      "[LightGBM] [Info] Number of positive: 82065, number of negative: 235590\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.574401 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 75135\n",
      "[LightGBM] [Info] Number of data points in the train set: 317655, number of used features: 455\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258346 -> initscore=-1.054581\n",
      "[LightGBM] [Info] Start training from score -1.054581\n",
      "Fitting estimator with 440 features.\n",
      "[LightGBM] [Info] Number of positive: 82065, number of negative: 235590\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.468340 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 72511\n",
      "[LightGBM] [Info] Number of data points in the train set: 317655, number of used features: 436\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258346 -> initscore=-1.054581\n",
      "[LightGBM] [Info] Start training from score -1.054581\n",
      "Fitting estimator with 420 features.\n",
      "[LightGBM] [Info] Number of positive: 82065, number of negative: 235590\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.426166 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 71616\n",
      "[LightGBM] [Info] Number of data points in the train set: 317655, number of used features: 416\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258346 -> initscore=-1.054581\n",
      "[LightGBM] [Info] Start training from score -1.054581\n",
      "Fitting estimator with 400 features.\n",
      "[LightGBM] [Info] Number of positive: 82065, number of negative: 235590\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.323747 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 69934\n",
      "[LightGBM] [Info] Number of data points in the train set: 317655, number of used features: 396\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258346 -> initscore=-1.054581\n",
      "[LightGBM] [Info] Start training from score -1.054581\n",
      "Fitting estimator with 380 features.\n",
      "[LightGBM] [Info] Number of positive: 82065, number of negative: 235590\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.255052 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 68485\n",
      "[LightGBM] [Info] Number of data points in the train set: 317655, number of used features: 377\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258346 -> initscore=-1.054581\n",
      "[LightGBM] [Info] Start training from score -1.054581\n",
      "Fitting estimator with 360 features.\n",
      "[LightGBM] [Info] Number of positive: 82065, number of negative: 235590\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.212418 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 66484\n",
      "[LightGBM] [Info] Number of data points in the train set: 317655, number of used features: 357\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258346 -> initscore=-1.054581\n",
      "[LightGBM] [Info] Start training from score -1.054581\n",
      "Fitting estimator with 340 features.\n",
      "[LightGBM] [Info] Number of positive: 82065, number of negative: 235590\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.182008 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 64078\n",
      "[LightGBM] [Info] Number of data points in the train set: 317655, number of used features: 337\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258346 -> initscore=-1.054581\n",
      "[LightGBM] [Info] Start training from score -1.054581\n",
      "Fitting estimator with 320 features.\n",
      "[LightGBM] [Info] Number of positive: 82065, number of negative: 235590\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.046082 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 62346\n",
      "[LightGBM] [Info] Number of data points in the train set: 317655, number of used features: 317\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258346 -> initscore=-1.054581\n",
      "[LightGBM] [Info] Start training from score -1.054581\n",
      "Fitting estimator with 300 features.\n",
      "[LightGBM] [Info] Number of positive: 82065, number of negative: 235590\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.988062 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 59913\n",
      "[LightGBM] [Info] Number of data points in the train set: 317655, number of used features: 297\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258346 -> initscore=-1.054581\n",
      "[LightGBM] [Info] Start training from score -1.054581\n",
      "Fitting estimator with 280 features.\n",
      "[LightGBM] [Info] Number of positive: 82065, number of negative: 235590\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.953462 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 58835\n",
      "[LightGBM] [Info] Number of data points in the train set: 317655, number of used features: 280\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258346 -> initscore=-1.054581\n",
      "[LightGBM] [Info] Start training from score -1.054581\n",
      "[LightGBM] [Info] Number of positive: 82065, number of negative: 235590\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.863958 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 54664\n",
      "[LightGBM] [Info] Number of data points in the train set: 317655, number of used features: 260\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258346 -> initscore=-1.054581\n",
      "[LightGBM] [Info] Start training from score -1.054581\n",
      "[LightGBM] [Info] Number of positive: 82065, number of negative: 235590\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.863746 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 54664\n",
      "[LightGBM] [Info] Number of data points in the train set: 317655, number of used features: 260\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258346 -> initscore=-1.054581\n",
      "[LightGBM] [Info] Start training from score -1.054581\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RFECV(cv=KFold(n_splits=5, random_state=None, shuffle=False),\n",
       "      estimator=LGBMClassifier(), scoring=&#x27;roc_auc&#x27;, step=20, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RFECV</label><div class=\"sk-toggleable__content\"><pre>RFECV(cv=KFold(n_splits=5, random_state=None, shuffle=False),\n",
       "      estimator=LGBMClassifier(), scoring=&#x27;roc_auc&#x27;, step=20, verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RFECV(cv=KFold(n_splits=5, random_state=None, shuffle=False),\n",
       "      estimator=LGBMClassifier(), scoring='roc_auc', step=20, verbose=1)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "lgbm = LGBMClassifier()\n",
    "# rfecv = RFECV(estimator=lgbm, step = 10, scoring='roc_auc')\n",
    "rfe = RFECV(estimator=lgbm, step=20, cv=KFold(n_splits=5, shuffle=False), scoring='roc_auc', verbose=1)\n",
    "\n",
    "rfe.fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "97aff2e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T19:01:46.612941Z",
     "iopub.status.busy": "2024-05-13T19:01:46.608504Z",
     "iopub.status.idle": "2024-05-13T19:01:46.623434Z",
     "shell.execute_reply": "2024-05-13T19:01:46.621907Z"
    },
    "papermill": {
     "duration": 0.10249,
     "end_time": "2024-05-13T19:01:46.626205",
     "exception": false,
     "start_time": "2024-05-13T19:01:46.523715",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal number of features : 260\n",
      "P_2_mean, P_2_std, D_39_mean, D_39_last, B_1_mean, B_1_std, B_2_mean, B_2_std, B_2_max, R_1_mean, R_1_last, S_3_mean, S_3_std, S_3_first, D_41_mean, D_41_std, B_3_mean, B_3_std, D_43_mean, D_43_std, D_43_last, D_44_mean, D_44_std, B_4_mean, B_4_std, D_45_mean, B_5_mean, B_5_min, B_5_last, R_2_last, D_46_std, D_46_min, D_46_first, D_46_last, D_47_mean, D_48_mean, D_48_std, D_49_mean, D_49_std, D_49_min, B_6_mean, B_6_min, B_6_first, B_6_last, B_7_mean, B_7_std, B_8_mean, D_50_mean, D_50_std, D_50_min, D_50_first, D_50_last, D_51_mean, B_9_mean, B_9_std, R_3_mean, R_3_std, R_3_first, R_3_last, D_52_mean, P_3_mean, P_3_std, P_3_min, P_3_max, P_3_first, P_3_last, B_10_mean, B_10_min, B_10_first, B_10_last, S_5_mean, S_5_min, S_5_first, S_5_last, D_54_mean, D_54_min, R_4_last, B_12_mean, S_8_mean, D_55_std, D_56_mean, D_56_std, R_5_last, D_58_mean, D_58_std, S_9_mean, S_9_min, S_9_last, B_14_mean, D_59_mean, D_59_std, D_60_mean, D_61_std, S_11_mean, S_11_min, S_11_max, S_11_first, S_11_last, D_62_mean, D_65_mean, D_65_last, B_16_mean, B_16_std, B_17_mean, B_17_std, B_17_min, B_17_last, B_19_std, B_20_std, S_12_mean, S_12_min, S_12_last, R_6_mean, R_6_last, B_21_mean, B_21_first, B_21_last, D_69_mean, D_69_min, B_22_first, D_70_mean, D_70_std, D_71_mean, D_72_mean, S_15_mean, S_15_max, S_15_last, R_7_mean, R_7_last, B_25_mean, B_26_mean, B_26_last, D_78_std, R_9_mean, S_16_mean, S_16_first, R_10_last, R_11_mean, R_11_last, B_27_std, D_82_mean, D_82_std, R_12_mean, R_12_std, B_28_mean, D_83_mean, D_83_std, R_14_mean, R_20_last, D_91_min, S_22_mean, S_22_std, S_22_max, S_22_first, S_22_last, S_23_mean, S_23_std, S_23_last, S_25_std, S_25_max, S_25_last, S_26_mean, D_102_std, D_105_mean, D_105_std, D_106_mean, B_36_mean, B_36_std, B_36_min, R_26_mean, R_27_mean, D_108_mean, D_112_mean, D_112_std, D_112_last, B_40_mean, B_40_min, B_40_first, B_40_last, S_27_last, D_115_mean, D_121_mean, D_122_mean, D_123_mean, D_123_max, D_124_mean, D_128_mean, D_129_mean, D_133_mean, D_133_std, D_139_mean, D_140_mean, D_140_last, D_144_mean, D_144_std, D_145_mean, B_1_last_lag_sub, B_2_last_lag_sub, R_1_last_lag_sub, S_3_last_lag_sub, B_3_last_lag_sub, D_44_last_lag_sub, B_4_last_lag_sub, B_5_last_lag_sub, D_47_last_lag_sub, D_48_last_lag_sub, D_49_last_lag_sub, B_6_last_lag_sub, B_7_last_lag_sub, D_50_last_lag_sub, B_9_last_lag_sub, D_52_last_lag_sub, S_5_last_lag_sub, S_8_last_lag_sub, D_55_last_lag_sub, D_58_last_lag_sub, S_9_last_lag_sub, B_14_last_lag_sub, D_60_last_lag_sub, B_18_last_lag_sub, B_20_last_lag_sub, S_12_last_lag_sub, S_13_last_lag_sub, P_4_last_lag_sub, R_7_last_lag_sub, B_25_last_lag_sub, B_26_last_lag_sub, D_78_last_lag_sub, S_16_last_lag_sub, D_80_last_lag_sub, D_81_last_lag_sub, D_82_last_lag_sub, R_12_last_lag_sub, B_28_last_lag_sub, S_22_last_lag_sub, S_23_last_lag_sub, D_102_last_lag_sub, D_104_last_lag_sub, D_105_last_lag_sub, D_112_last_lag_sub, D_118_last_lag_sub, D_121_last_lag_sub, D_123_last_lag_sub, D_133_last_lag_sub, D_144_last_lag_sub, B_30_0_count, B_30_0_last, B_38_2_first, D_114_1_last, D_117_1_first, D_120_0_last, D_120_1_last, D_120_1_nunique, D_63_2_first, D_63_3_first, D_63_4_last, D_64_0_last, D_66_1_first, D_66_1_nunique, D_66_2_first\n"
     ]
    }
   ],
   "source": [
    "selected_features = np.array(selected_columns)[rfe.get_support()]\n",
    "print(\"Optimal number of features : %d\" % rfe.n_features_)\n",
    "print(', '.join(selected_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d487a3",
   "metadata": {
    "papermill": {
     "duration": 0.078191,
     "end_time": "2024-05-13T19:01:46.783230",
     "exception": false,
     "start_time": "2024-05-13T19:01:46.705039",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "L1 Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855be8e8",
   "metadata": {
    "papermill": {
     "duration": 0.077288,
     "end_time": "2024-05-13T19:01:46.939653",
     "exception": false,
     "start_time": "2024-05-13T19:01:46.862365",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Training and Testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f5bacb18",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T19:01:47.098557Z",
     "iopub.status.busy": "2024-05-13T19:01:47.097901Z",
     "iopub.status.idle": "2024-05-13T19:01:47.114983Z",
     "shell.execute_reply": "2024-05-13T19:01:47.113837Z"
    },
    "papermill": {
     "duration": 0.099683,
     "end_time": "2024-05-13T19:01:47.117495",
     "exception": false,
     "start_time": "2024-05-13T19:01:47.017812",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def amex_metric(y_true: pd.DataFrame, y_pred: pd.DataFrame) -> float:\n",
    "\n",
    "    def top_four_percent_captured(y_true: pd.DataFrame, y_pred: pd.DataFrame) -> float:\n",
    "        df = (pd.concat([y_true, y_pred], axis='columns')\n",
    "              .sort_values('prediction', ascending=False))\n",
    "        df['weight'] = df['target'].apply(lambda x: 20 if x==0 else 1)\n",
    "        four_pct_cutoff = int(0.04 * df['weight'].sum())\n",
    "        df['weight_cumsum'] = df['weight'].cumsum()\n",
    "        df_cutoff = df.loc[df['weight_cumsum'] <= four_pct_cutoff]\n",
    "        return (df_cutoff['target'] == 1).sum() / (df['target'] == 1).sum()\n",
    "        \n",
    "    def weighted_gini(y_true: pd.DataFrame, y_pred: pd.DataFrame) -> float:\n",
    "        df = (pd.concat([y_true, y_pred], axis='columns')\n",
    "              .sort_values('prediction', ascending=False))\n",
    "        df['weight'] = df['target'].apply(lambda x: 20 if x==0 else 1)\n",
    "        df['random'] = (df['weight'] / df['weight'].sum()).cumsum()\n",
    "        total_pos = (df['target'] * df['weight']).sum()\n",
    "        df['cum_pos_found'] = (df['target'] * df['weight']).cumsum()\n",
    "        df['lorentz'] = df['cum_pos_found'] / total_pos\n",
    "        df['gini'] = (df['lorentz'] - df['random']) * df['weight']\n",
    "        return df['gini'].sum()\n",
    "\n",
    "    def normalized_weighted_gini(y_true: pd.DataFrame, y_pred: pd.DataFrame) -> float:\n",
    "        y_true_pred = y_true.rename(columns={'target': 'prediction'})\n",
    "        return weighted_gini(y_true, y_pred) / weighted_gini(y_true, y_true_pred)\n",
    "\n",
    "    g = normalized_weighted_gini(y_true, y_pred)\n",
    "    d = top_four_percent_captured(y_true, y_pred)\n",
    "\n",
    "    return 0.5 * (g + d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1532d8",
   "metadata": {
    "papermill": {
     "duration": 0.08016,
     "end_time": "2024-05-13T19:01:47.275667",
     "exception": false,
     "start_time": "2024-05-13T19:01:47.195507",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Random Forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fd403c29",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T19:01:47.436165Z",
     "iopub.status.busy": "2024-05-13T19:01:47.435372Z",
     "iopub.status.idle": "2024-05-13T19:01:47.513167Z",
     "shell.execute_reply": "2024-05-13T19:01:47.512026Z"
    },
    "papermill": {
     "duration": 0.160557,
     "end_time": "2024-05-13T19:01:47.515465",
     "exception": false,
     "start_time": "2024-05-13T19:01:47.354908",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 317655 entries, 308385 to 123348\n",
      "Columns: 720 entries, P_2_mean to D_68_6_nunique\n",
      "dtypes: float32(284), float64(115), int16(14), int64(133), int8(174)\n",
      "memory usage: 1008.8 MB\n"
     ]
    }
   ],
   "source": [
    "x_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8fd95fdd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T19:01:47.677836Z",
     "iopub.status.busy": "2024-05-13T19:01:47.676802Z",
     "iopub.status.idle": "2024-05-13T19:23:49.996761Z",
     "shell.execute_reply": "2024-05-13T19:23:49.994881Z"
    },
    "papermill": {
     "duration": 1322.406503,
     "end_time": "2024-05-13T19:23:50.000390",
     "exception": false,
     "start_time": "2024-05-13T19:01:47.593887",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93    101094\n",
      "           1       0.81      0.78      0.79     35044\n",
      "\n",
      "    accuracy                           0.90    136138\n",
      "   macro avg       0.87      0.86      0.86    136138\n",
      "weighted avg       0.89      0.90      0.90    136138\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhkAAAGdCAYAAAC/02HYAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABF5UlEQVR4nO3de1hVZfr/8TegHMTAPAAyHstKLdM8hLuyyYmkxCbKSsyUFC0bZFTyWA6aHWiwxsN4IKsJv5mTOpOWkDiEqZOSKIanEbNRI9ONmCJJCsjevz/6sXIvsaBZO7A+r7nWdcV67v2sZzWpt/dz2B5Op9OJiIiIiMU863oAIiIi8sukJENERETcQkmGiIiIuIWSDBEREXELJRkiIiLiFkoyRERExC2UZIiIiIhbKMkQERERt1CSISIiIm7RoK4HUKXixMG6HoJIveMX2qeuhyBSL50v/8qt/Vv5Z1LD5ldZ1tflpt4kGSIiIvWGo7KuR/CLoOkSERERcQtVMkRERMycjroewS+CkgwREREzh5IMKyjJEBERMXGqkmEJrckQERERt1AlQ0RExEzTJZZQkiEiImKm6RJLaLpERERE3EKVDBERETMdxmUJJRkiIiJmmi6xhKZLRERExC1UyRARETHT7hJLqJIhIiJi4nQ6LLtq45tvvmHcuHG0bdsWPz8/brnlFrZt23bBuJwkJibSsmVL/Pz8CA8P58CBAy59nDx5kiFDhhAQEECTJk2IjY3lzJkzLjG7du2iT58++Pr60rp1a5KTky8ay8qVK+nYsSO+vr506dKFDz74oFbvAkoyRERE6o2RI0eSmZnJW2+9xe7du+nXrx/h4eF89dV3X22fnJzMvHnzSElJYevWrfj7+xMREcG5c+eMPoYMGcLevXvJzMwkLS2NTZs28fjjjxvtJSUl9OvXj7Zt25Kbm8usWbOYMWMGixcvNmK2bNnC4MGDiY2N5dNPPyUqKoqoqCj27NlTq/fxcDqdzv/x34klKk4crOshiNQ7fqF96noIIvXS+fKv3Np/2YEtlvXlc80tNYo7e/YsV1xxBe+99x6RkZHG/R49enDPPffw3HPPERoaylNPPcWECRMAOH36NMHBwaSmphIdHc2+ffvo3Lkz27Zto2fPngBkZGTQv39/jhw5QmhoKIsWLeKZZ57Bbrfj7e0NwJQpU1i9ejX5+fkADBo0iNLSUtLS0oxx9O7dm27dupGSklLjd1clQ0RExMzpsOwqKyujpKTE5SorK7vokefPn6eyshJfX1+X+35+fnz88cccOnQIu91OeHi40RYYGEhYWBjZ2dkAZGdn06RJEyPBAAgPD8fT05OtW7caMbfffruRYABERESwf/9+Tp06ZcRc+JyqmKrn1JSSDBERETNHpWVXUlISgYGBLldSUtJFj7ziiiuw2Ww899xzHD16lMrKSpYuXUp2djbHjh3DbrcDEBwc7PK54OBgo81utxMUFOTS3qBBA5o2beoSU10fVW0/FFPVXlNKMkRERNxo6tSpnD592uWaOnVqtbFvvfUWTqeT3/zmN/j4+DBv3jwGDx6Mp+fl+cf15TlqERERd7JwusTHx4eAgACXy8fHp9rHXn311WzcuJEzZ87w5ZdfkpOTQ0VFBVdddRUhISEAFBYWunymsLDQaAsJCeH48eMu7efPn+fkyZMuMdX1UdX2QzFV7TWlJENERMTM4bDu+gn8/f1p2bIlp06dYt26ddx33320b9+ekJAQsrKyjLiSkhK2bt2KzWYDwGazUVxcTG5urhGzfv16HA4HYWFhRsymTZuoqKgwYjIzM7nuuuu48sorjZgLn1MVU/WcmlKSISIiUk+sW7eOjIwMDh06RGZmJn379qVjx44MHz4cDw8Pxo0bx/PPP8/777/P7t27GTZsGKGhoURFRQHQqVMn7r77bkaNGkVOTg6bN29mzJgxREdHExoaCsAjjzyCt7c3sbGx7N27l+XLlzN37lwSEhKMcYwdO5aMjAxeeeUV8vPzmTFjBtu3b2fMmDG1eh+d+CkiImJWR99dUrVe48iRIzRt2pSBAwfywgsv0LBhQwAmTZpEaWkpjz/+OMXFxdx2221kZGS47Eh5++23GTNmDHfeeSeenp4MHDiQefPmGe2BgYH861//Ii4ujh49etC8eXMSExNdztK45ZZbWLZsGdOmTePpp5/mmmuuYfXq1dxwww21eh+dkyFSj+mcDJHquf2cjF3rLOvL58YIy/q63Gi6RERERNxC0yUiIiImTmdlXQ/hF0FJhoiIiFkdrcn4pdF0iYiIiLiFKhkiIiJmP/F8C3GlJENERMRM0yWWUJIhIiJi5tDCTytoTYaIiIi4hSoZIiIiZpousYSSDBERETMt/LSEpktERETELVTJEBERMdN0iSWUZIiIiJhpusQSmi4RERERt1AlQ0RExEyVDEsoyRARETHRt7BaQ9MlIiIi4haqZIiIiJhpusQSSjJERETMtIXVEkoyREREzFTJsITWZIiIiIhbqJIhIiJipukSSyjJEBERMdN0iSU0XSIiIiJuoUqGiIiImaZLLKEkQ0RExEzTJZbQdImIiIi4hSoZIiIiZqpkWEJJhoiIiJnWZFhC0yUiIiLiFqpkiIiImGm6xBKqZIiIiJg5HdZdtVBZWcmf/vQn2rdvj5+fH1dffTXPPfccTqfz+6E5nSQmJtKyZUv8/PwIDw/nwIEDLv2cPHmSIUOGEBAQQJMmTYiNjeXMmTMuMbt27aJPnz74+vrSunVrkpOTLxrPypUr6dixI76+vnTp0oUPPvigVu+jJENERMTM4bDuqoU///nPLFq0iPnz57Nv3z7+/Oc/k5yczF//+lcjJjk5mXnz5pGSksLWrVvx9/cnIiKCc+fOGTFDhgxh7969ZGZmkpaWxqZNm3j88ceN9pKSEvr160fbtm3Jzc1l1qxZzJgxg8WLFxsxW7ZsYfDgwcTGxvLpp58SFRVFVFQUe/bsqfH7eDgvTI/qUMWJg3U9BJF6xy+0T10PQaReOl/+lVv7P7vqJcv68rt/So1jBwwYQHBwMG+88YZxb+DAgfj5+bF06VKcTiehoaE89dRTTJgwAYDTp08THBxMamoq0dHR7Nu3j86dO7Nt2zZ69uwJQEZGBv379+fIkSOEhoayaNEinnnmGex2O97e3gBMmTKF1atXk5+fD8CgQYMoLS0lLS3NGEvv3r3p1q0bKSkpNXofVTJERETMLJwuKSsro6SkxOUqKyur9rG33HILWVlZfPbZZwDs3LmTjz/+mHvuuQeAQ4cOYbfbCQ8PNz4TGBhIWFgY2dnZAGRnZ9OkSRMjwQAIDw/H09OTrVu3GjG33367kWAAREREsH//fk6dOmXEXPicqpiq59SEkgwREREzC6dLkpKSCAwMdLmSkpKqfeyUKVOIjo6mY8eONGzYkJtuuolx48YxZMgQAOx2OwDBwcEunwsODjba7HY7QUFBLu0NGjSgadOmLjHV9XHhMy4VU9VeE9pdIiIi4kZTp04lISHB5Z6Pj0+1sStWrODtt99m2bJlXH/99eTl5TFu3DhCQ0OJiYn5OYZrKSUZIiIiZhZuYfXx8blkUmE2ceJEo5oB0KVLF7744guSkpKIiYkhJCQEgMLCQlq2bGl8rrCwkG7dugEQEhLC8ePHXfo9f/48J0+eND4fEhJCYWGhS0zVzz8WU9VeE5ouERERMXM6rbtq4dtvv8XT0/WPZi8vLxz/P+lp3749ISEhZGVlGe0lJSVs3boVm80GgM1mo7i4mNzcXCNm/fr1OBwOwsLCjJhNmzZRUVFhxGRmZnLddddx5ZVXGjEXPqcqpuo5NaEkQ0REpJ649957eeGFF0hPT+fw4cOsWrWKv/zlL9x///0AeHh4MG7cOJ5//nnef/99du/ezbBhwwgNDSUqKgqATp06cffddzNq1ChycnLYvHkzY8aMITo6mtDQUAAeeeQRvL29iY2NZe/evSxfvpy5c+e6TOuMHTuWjIwMXnnlFfLz85kxYwbbt29nzJgxNX4fbWEVqce0hVWkem7fwvr36Zb15Tf42RrHfvPNN/zpT39i1apVHD9+nNDQUAYPHkxiYqKxE8TpdDJ9+nQWL15McXExt912GwsXLuTaa681+jl58iRjxoxhzZo1eHp6MnDgQObNm0fjxo2NmF27dhEXF8e2bdto3rw58fHxTJ482WU8K1euZNq0aRw+fJhrrrmG5ORk+vfvX+P3UZIhUo8pyRCpntuTjLf/ZFlffkOes6yvy42mS0RERMQttLtERETETF/1bgklGSIiImb6FlZLKMkQERExqx/LFS97WpMhIiIibqFKhoiIiJmmSyyhJENERMRMSYYlNF0iIiIibqFKhoiIiJm2sFpCSYaIiIiJ06HdJVbQdImIiIi4hSoZIiIiZlr4aQklGSIiImZak2EJTZeIiIiIW6iSISIiYqaFn5ZQkiEiImKmNRmWUJIhIiJipiTDElqTISIiIm6hSoaIiIiZvurdEqpk/AKUln7LS3NSuOuBGHr0vY8hTySwe9/+amOfTf4rN9x6D28tX1Vte3l5OQNj4rjh1nvI/+y/1cYUHDnKzeEPYIt40OV+xfnzLPrb29z90HC69/09D8T8gY8/2f6/vZyIhUJDQ1iSOo/CY3v45vTnfLrjQ3p0v9ElpmPHDqx6902+LtrH6VMHyN6STuvWodX2l/b+W5wv/4rf/z7C5f758q8uuh5++Pduey9xA4fDuutXTJWMX4DEl+by+cHDJCVOIKh5M9asW8+osU/z3tuvEtyiuRH34cbN7NqbT1DzZpfs65WFfyOoeVP2f36w2vaK8+eZOP0lenS9nrw9+1za/rp4CWnrPmLG5D/Svm1rNufkMnbqcyx99RU6XdvBmpcV+YmaNAlk04bVbNi4hQH3PkrRia+5pkN7ThWfNmKuuqotGz9azZupf+fZmS9TUnKGzp2v5dy5sov6G/vHUTh/4G+7I2LHs+5fHxk/FxeXWPtCIpcBVTIuc+fKyvhw48ckxMXSs1sX2rQKJS72Udq0CmX5qnQjrrDoBEmzF/Hn6ZNo0MCr2r7+nb2NLTk7mDBm5CWf99fFS2jftjURv7v9orY1GesZNWwQt99yM61/05Lo+wfQx9aL1L+/+7+/qMj/aNLEP3DkyFFGjkpg2/Y8Dh/+kswPN3Hw4BdGzHMzJ7M2Yz1Tpr5AXt5eDh78grS0TIqKvnbpq2vX6xk/7glGPv7UJZ9XfPo0hYVFxlVWdnGiIvWYw2nd9SumJOMyV3m+kspKBz7eDV3u+/h4s2PXXgAcDgdTZ77MY488SIer2lbbz4mTp5jx57kk/WkCvr6+1cZszc3jXx99zLSn/lBte3lFBd7e3heN49P/Pw6RujRgQD9yc3fxzt9f5eiRnWzLWUfsiEeMdg8PD/rfcycHDhzkg7S3OXpkJ1s+XnPRVIifny9v/d984sc+TWFh0SWf99e5L2A/upvszWk8FjPIbe8lbuJ0WHf9itU6yThx4gTJycncf//92Gw2bDYb999/P7NmzaKo6NK/4MQ9/P0b0fWGTqSk/p3jRV9TWVnJmnXr2bknnxMnTgLwxtKVeHl58uhD91Xbh9PpZNoLf+HhqEhu6HRttTHFp0t45oW/8PwzCTT296825tawHvzfO+/yxZdf4XA42JKzg6yNWyj6+qQ1LyvyP7iqfRueeGIon39+iP4DHuHVV/+PObNnMnToQwAEBTXniisaM2liHOv+tYF7Ih9h9XsZ/GPF69zep7fRzysvP0t29nbWrPnXJZ81fcYsBj8ymrv7R/Puqg+Y/9cXGRM3wu3vKFLf1GpNxrZt24iIiKBRo0aEh4dz7bXf/YFUWFjIvHnzeOmll1i3bh09e/b8wX7KysouKh16lpXh4+NTy+ELQNKfJpCYNJvfRT2Kl5cnna7twD3hv+U/+z9nb/4Blq58j5V/+yseHh7Vfv7tf7xP6bffMnLow5d8xvSX5hJ51x307NblkjFTxj7BjD/P495HHsfDA1qHtiQq8i5WpV36N2ORn4unpye5ubuY9qeXAMjL28v111/HE6OG8tZbK/H0/O7vXO+vWcfcea8BsHPnXmy2njz++FA2/fsTBgy4i7533ErPm/v94LNeeHGO8c95eXvx92/EUwlPMn/B39zzcmK9X/k0h1VqlWTEx8fz0EMPkZKSctEfWE6nk9GjRxMfH092dvYP9pOUlMSzzz7rcm/axD+SOGlsbYYj/1+bVqGkLpjFt2fPUVr6LS2aN+WpPyXRKjSEHTv3cPJUMXcNHGbEV1Y6mDX/dd5asZp//XMJObk72bknn+59XVe/Dxr5RyLv6suLf5pAzo6dbNj8Cal//yfw3e4uh8NB19sjmT7pjzwwIIKmVzZh3kuJlJWVU1xSQlDzZsxe9DdahYb8rP8+RKpz7Nhx/rPvM5d7+fmf88D9/QE4ceIkFRUV7Nt3wBRzgFtvuRmAvnfcxtVXt+XrItdFzyuXv8bHH2/lzrseqvbZOTmfMu2Z8Xh7e1NeXm7VK4kbOX/lu0KsUqskY+fOnaSmplb7N2IPDw/Gjx/PTTfd9KP9TJ06lYSEBJd7nt98VZuhSDUa+fnSyM+X0yXfsCUnl4Q/jOCuO26jdy/X/0+eGD+Ne+/+HVH9v/vb2NRxo4l//Psk5HjR1zyRMI2Xn51Kl+uvA2Dpq3/BccEvuvX/zuZvS1ey9NW/XLRbxcfHm+AWzak4f57MDZurXSQq8nPbkr2N66692uXetddcRUHBd7/3VFRUsH37Tq41xVxzzVV8UXAEgORZ8/nbm8tc2nd+up6nJswgLT3zks/u2vV6Tp48pQRDfnVqlWSEhISQk5NDx44dq23PyckhODj4R/vx8fG5aGqkovxEbYYiF9i8NRen00m7Nq0oOHKUVxa8Qfs2rYiK7EfDBg1oEhjgEt+ggRfNm15J+7atAGgZEuTS3sjPD4DWv2lJSFALAK5u18YlZu++A3h6enLNVe2Me7v25lNY9DUdr7mK40Vfs/BvS3E6nYwY4nqehkhdmDv3Nf696T2mTI5n5T/W0KtXN0aOHMLoP0wyYl7+yyL+/vYi/v3vT9iwcQsR/e5gQORd3Bn+3X/DVTtFzAq+/IrDh78EYEDkXQQFNWdrzg7OnSsj/M7bmTI5nr/MTvl5XlSsoekSS9QqyZgwYQKPP/44ubm53HnnnUZCUVhYSFZWFq+99hovv/yyWwYql/bNmVLmpLxJYdEJAgOu4K7f3sYfn4ihYYOf9xiUsvJy/vraEo4ctdPIz48+tl4k/WkiAVc0/lnHIVKd7bk7efChkTz//BSmPTOOQ4e/JOGp6fz9798fTPfeexn8IW4KkyfFM2f2TPZ/dpCHBo1i85ZtNX5ORUUFTz75GK+8PAMPDw8+/+9hJkx8ltffeNsdryXu8ivfFWIVD+cPnSZTjeXLlzN79mxyc3OprKwEwMvLix49epCQkMDDD1968eAPqThR/eFPIr9mfqF96noIIvXS+XL3TrGXzhxiWV/+ib/eBLPWf9UdNGgQgwYNoqKighMnvpviaN68OQ0bNvyRT4qIiMivyU8+jKthw4a0bNmSli1bKsEQEZFfljr67pJ27drh4eFx0RUXFwfAuXPniIuLo1mzZjRu3JiBAwdSWFjo0kdBQQGRkZE0atSIoKAgJk6cyPnz511iNmzYQPfu3fHx8aFDhw6kpqZeNJYFCxbQrl07fH19CQsLIycnp3b/DtGJnyIiIhero2PFt23bxrFjx4wrM/O7XUsPPfTd9ujx48ezZs0aVq5cycaNGzl69CgPPPCA8fnKykoiIyMpLy9ny5YtLFmyhNTUVBITE42YQ4cOERkZSd++fcnLy2PcuHGMHDmSdevWGTHLly8nISGB6dOns2PHDrp27UpERATHjx+v1fvUek2Gu2hNhsjFtCZDpHpuX5ORGG1ZX/4z3/nJnx03bhxpaWkcOHCAkpISWrRowbJly3jwwe92POXn59OpUyeys7Pp3bs3a9euZcCAARw9etTYnJGSksLkyZMpKirC29ubyZMnk56ezp49e4znREdHU1xcTEZGBgBhYWH06tWL+fPnA9+di9S6dWvi4+OZMmVKjcevSoaIiIhZPfjukvLycpYuXcqIESPw8PAgNzeXiooKwsPDjZiOHTvSpk0b4xDM7OxsunTp4nKcREREBCUlJezdu9eIubCPqpiqPsrLy8nNzXWJ8fT0JDw8/EcP2zTTV72LiIiYWXhORnVfpVHdeVFmq1evpri4mMceewwAu92Ot7c3TZo0cYkLDg7GbrcbMebzqqp+/rGYkpISzp49y6lTp6isrKw2Jj8//8df+AKqZIiIiLhRUlISgYGBLldSUtKPfu6NN97gnnvuITQ09GcYpXuokiEiImJi5XeXVPdVGj9Wxfjiiy/48MMPeffdd417ISEhlJeXU1xc7FLNKCwsJCQkxIgx7wKp2n1yYYx5R0phYSEBAQH4+fnh5eWFl5dXtTFVfdSUKhkiIiJmFu4u8fHxISAgwOX6sSTjzTffJCgoiMjISONejx49aNiwIVlZWca9/fv3U1BQgM1mA8Bms7F7926XXSCZmZkEBATQuXNnI+bCPqpiqvrw9vamR48eLjEOh4OsrCwjpqZUyRAREalHHA4Hb775JjExMTS44OshAgMDiY2NJSEhgaZNmxIQEEB8fDw2m43evXsD0K9fPzp37szQoUNJTk7Gbrczbdo04uLijMRm9OjRzJ8/n0mTJjFixAjWr1/PihUrSE9PN56VkJBATEwMPXv25Oabb2bOnDmUlpYyfPjwWr2LkgwRERGzOvyCtA8//JCCggJGjBhxUdvs2bPx9PRk4MCBlJWVERERwcKFC412Ly8v0tLSePLJJ7HZbPj7+xMTE8PMmTONmPbt25Oens748eOZO3curVq14vXXXyciIsKIGTRoEEVFRSQmJmK32+nWrRsZGRk1+hLUC+mcDJF6TOdkiFTP3edknJlwn2V9NX75Pcv6utyokiEiImKmr3q3hBZ+ioiIiFuokiEiImLiVCXDEkoyREREzJRkWELTJSIiIuIWqmSIiIiYWXji56+ZkgwREREzTZdYQtMlIiIi4haqZIiIiJipkmEJJRkiIiIm9eQw7MuepktERETELVTJEBERMdN0iSWUZIiIiJgpybCEkgwRERETHStuDa3JEBEREbdQJUNERMRMlQxLKMkQEREx06niltB0iYiIiLiFKhkiIiImWvhpDSUZIiIiZkoyLKHpEhEREXELVTJERETMtPDTEkoyRERETLQmwxqaLhERERG3UCVDRETETNMlllCSISIiYqLpEmsoyRARETFTJcMSWpMhIiIibqFKhoiIiIlTlQxLKMkQERExU5JhCU2XiIiIiFuokiEiImKi6RJrqJIhIiJi5rDwqqWvvvqKRx99lGbNmuHn50eXLl3Yvn270e50OklMTKRly5b4+fkRHh7OgQMHXPo4efIkQ4YMISAggCZNmhAbG8uZM2dcYnbt2kWfPn3w9fWldevWJCcnXzSWlStX0rFjR3x9fenSpQsffPBBrd5FSYaIiEg9cerUKW699VYaNmzI2rVr+c9//sMrr7zClVdeacQkJyczb948UlJS2Lp1K/7+/kRERHDu3DkjZsiQIezdu5fMzEzS0tLYtGkTjz/+uNFeUlJCv379aNu2Lbm5ucyaNYsZM2awePFiI2bLli0MHjyY2NhYPv30U6KiooiKimLPnj01fh8Pp9NZL04cqThxsK6HIFLv+IX2qeshiNRL58u/cmv/RXf91rK+WmRurHHslClT2Lx5M//+97+rbXc6nYSGhvLUU08xYcIEAE6fPk1wcDCpqalER0ezb98+OnfuzLZt2+jZsycAGRkZ9O/fnyNHjhAaGsqiRYt45plnsNvteHt7G89evXo1+fn5AAwaNIjS0lLS0tKM5/fu3Ztu3bqRkpJSo/dRJUNERMTE6bDuKisro6SkxOUqKyur9rnvv/8+PXv25KGHHiIoKIibbrqJ1157zWg/dOgQdrud8PBw415gYCBhYWFkZ2cDkJ2dTZMmTYwEAyA8PBxPT0+2bt1qxNx+++1GggEQERHB/v37OXXqlBFz4XOqYqqeUxNKMkREREysTDKSkpIIDAx0uZKSkqp97sGDB1m0aBHXXHMN69at48knn+SPf/wjS5YsAcButwMQHBzs8rng4GCjzW63ExQU5NLeoEEDmjZt6hJTXR8XPuNSMVXtNaHdJSIiIm40depUEhISXO75+PhUG+twOOjZsycvvvgiADfddBN79uwhJSWFmJgYt4/VaqpkiIiImDk9LLt8fHwICAhwuS6VZLRs2ZLOnTu73OvUqRMFBQUAhISEAFBYWOgSU1hYaLSFhIRw/Phxl/bz589z8uRJl5jq+rjwGZeKqWqvCSUZIiIiJlZOl9TGrbfeyv79+13uffbZZ7Rt2xaA9u3bExISQlZWltFeUlLC1q1bsdlsANhsNoqLi8nNzTVi1q9fj8PhICwszIjZtGkTFRUVRkxmZibXXXedsZPFZrO5PKcqpuo5NaEkQ0REpJ4YP348n3zyCS+++CKff/45y5YtY/HixcTFxQHg4eHBuHHjeP7553n//ffZvXs3w4YNIzQ0lKioKOC7ysfdd9/NqFGjyMnJYfPmzYwZM4bo6GhCQ0MBeOSRR/D29iY2Npa9e/eyfPly5s6d6zKtM3bsWDIyMnjllVfIz89nxowZbN++nTFjxtT4fbSFVaQe0xZWkeq5ewvrsdv6WtZXy48/qlV8WloaU6dO5cCBA7Rv356EhARGjRpltDudTqZPn87ixYspLi7mtttuY+HChVx77bVGzMmTJxkzZgxr1qzB09OTgQMHMm/ePBo3bmzE7Nq1i7i4OLZt20bz5s2Jj49n8uTJLmNZuXIl06ZN4/Dhw1xzzTUkJyfTv3//Gr+LkgyRekxJhkj13J1kHL3FuiQjdEvtkoxfEk2XiIiIiFtoC6uIiIiJ0+lR10P4RVCSISIiYqJvYbWGpktERETELVTJEBERMXE6NF1iBSUZIiIiJvVj3+XlT0mGiIiIiSoZ1tCaDBEREXELVTJERERMVMmwhpIMERERE63JsIamS0RERMQtVMkQEREx0XSJNZRkiIiImOhYcWtoukRERETcQpUMERERE313iTWUZIiIiJg4NF1iCU2XiIiIiFuokiEiImKihZ/WUJIhIiJioi2s1lCSISIiYqITP62hNRkiIiLiFqpkiIiImGi6xBpKMkREREy0hdUami4RERERt1AlQ0RExERbWK2hJENERMREu0usoekSERERcQtVMkREREy08NMaSjJERERMtCbDGpouEREREbdQJUNERMRECz+toUqGiIiIicPpYdlVGzNmzMDDw8Pl6tixo9F+7tw54uLiaNasGY0bN2bgwIEUFha69FFQUEBkZCSNGjUiKCiIiRMncv78eZeYDRs20L17d3x8fOjQoQOpqakXjWXBggW0a9cOX19fwsLCyMnJqdW7QD2qZPj/5va6HoJIvRPdMqyuhyDyq1SXazKuv/56PvzwQ+PnBg2+/6N6/PjxpKens3LlSgIDAxkzZgwPPPAAmzdvBqCyspLIyEhCQkLYsmULx44dY9iwYTRs2JAXX3wRgEOHDhEZGcno0aN5++23ycrKYuTIkbRs2ZKIiAgAli9fTkJCAikpKYSFhTFnzhwiIiLYv38/QUFBNX4XD6ezfhSFvH1a1fUQROqdh0NurushiNRLS7941639b/vN/Zb11eurVTWOnTFjBqtXryYvL++ittOnT9OiRQuWLVvGgw8+CEB+fj6dOnUiOzub3r17s3btWgYMGMDRo0cJDg4GICUlhcmTJ1NUVIS3tzeTJ08mPT2dPXv2GH1HR0dTXFxMRkYGAGFhYfTq1Yv58+cD4HA4aN26NfHx8UyZMqXG76PpEhERERMrp0vKysooKSlxucrKyi757AMHDhAaGspVV13FkCFDKCgoACA3N5eKigrCw8ON2I4dO9KmTRuys7MByM7OpkuXLkaCARAREUFJSQl79+41Yi7soyqmqo/y8nJyc3NdYjw9PQkPDzdiakpJhoiIiInTwispKYnAwECXKykpqdrnhoWFkZqaSkZGBosWLeLQoUP06dOHb775Brvdjre3N02aNHH5THBwMHa7HQC73e6SYFS1V7X9UExJSQlnz57lxIkTVFZWVhtT1UdN1Zs1GSIiIr9EU6dOJSEhweWej49PtbH33HOP8c833ngjYWFhtG3blhUrVuDn5+fWcbqDkgwRERETK0/89PHxuWRS8WOaNGnCtddey+eff85dd91FeXk5xcXFLtWMwsJCQkJCAAgJCbloF0jV7pMLY8w7UgoLCwkICMDPzw8vLy+8vLyqjanqo6Y0XSIiImLidHpYdv0vzpw5w3//+19atmxJjx49aNiwIVlZWUb7/v37KSgowGazAWCz2di9ezfHjx83YjIzMwkICKBz585GzIV9VMVU9eHt7U2PHj1cYhwOB1lZWUZMTSnJEBERqScmTJjAxo0bOXz4MFu2bOH+++/Hy8uLwYMHExgYSGxsLAkJCXz00Ufk5uYyfPhwbDYbvXv3BqBfv3507tyZoUOHsnPnTtatW8e0adOIi4szqimjR4/m4MGDTJo0ifz8fBYuXMiKFSsYP368MY6EhARee+01lixZwr59+3jyyScpLS1l+PDhtXofTZeIiIiYOOrouUeOHGHw4MF8/fXXtGjRgttuu41PPvmEFi1aADB79mw8PT0ZOHAgZWVlREREsHDhQuPzXl5epKWl8eSTT2Kz2fD39ycmJoaZM2caMe3btyc9PZ3x48czd+5cWrVqxeuvv26ckQEwaNAgioqKSExMxG63061bNzIyMi5aDPpjdE6GSD2mczJEqufuczI2hTxkWV+321da1tflRtMlIiIi4haaLhERETFx1Isa/+VPSYaIiIiJg7r77pJfEiUZIiIiJk4lGZbQmgwRERFxC1UyRERETOpqC+svjZIMERERE02XWEPTJSIiIuIWqmSIiIiYaLrEGkoyRERETJRkWEPTJSIiIuIWqmSIiIiYaOGnNZRkiIiImDiUY1hC0yUiIiLiFqpkiIiImOi7S6yhJENERMREX8JqDSUZIiIiJtrCag2tyRARERG3UCVDRETExOGhNRlWUJIhIiJiojUZ1tB0iYiIiLiFKhkiIiImWvhpDSUZIiIiJjrx0xqaLhERERG3UCVDRETERCd+WkNJhoiIiIl2l1hD0yUiIiLiFqpkiIiImGjhpzWUZIiIiJhoC6s1lGSIiIiYaE2GNbQmQ0RERNxCSYaIiIiJw8O666d66aWX8PDwYNy4cca9c+fOERcXR7NmzWjcuDEDBw6ksLDQ5XMFBQVERkbSqFEjgoKCmDhxIufPn3eJ2bBhA927d8fHx4cOHTqQmpp60fMXLFhAu3bt8PX1JSwsjJycnFq/g5IMERERE4eF10+xbds2Xn31VW688UaX++PHj2fNmjWsXLmSjRs3cvToUR544AGjvbKyksjISMrLy9myZQtLliwhNTWVxMREI+bQoUNERkbSt29f8vLyGDduHCNHjmTdunVGzPLly0lISGD69Ons2LGDrl27EhERwfHjx2v1Hh5Op7NeTD15+7Sq6yGI1DsPh9xc10MQqZeWfvGuW/t/rdWjlvU16sjSWsWfOXOG7t27s3DhQp5//nm6devGnDlzOH36NC1atGDZsmU8+OCDAOTn59OpUyeys7Pp3bs3a9euZcCAARw9epTg4GAAUlJSmDx5MkVFRXh7ezN58mTS09PZs2eP8czo6GiKi4vJyMgAICwsjF69ejF//nwAHA4HrVu3Jj4+nilTptT4XVTJEBERMbGyklFWVkZJSYnLVVZWdslnx8XFERkZSXh4uMv93NxcKioqXO537NiRNm3akJ2dDUB2djZdunQxEgyAiIgISkpK2Lt3rxFj7jsiIsLoo7y8nNzcXJcYT09PwsPDjZiaUpIhIiJi4vSw7kpKSiIwMNDlSkpKqva577zzDjt27Ki23W634+3tTZMmTVzuBwcHY7fbjZgLE4yq9qq2H4opKSnh7NmznDhxgsrKympjqvqoKW1hFRERcaOpU6eSkJDgcs/Hx+eiuC+//JKxY8eSmZmJr6/vzzU8t1KSISIiYmLlYVw+Pj7VJhVmubm5HD9+nO7duxv3Kisr2bRpE/Pnz2fdunWUl5dTXFzsUs0oLCwkJCQEgJCQkIt2gVTtPrkwxrwjpbCwkICAAPz8/PDy8sLLy6vamKo+akrTJSIiIiZ1sbvkzjvvZPfu3eTl5RlXz549GTJkiPHPDRs2JCsry/jM/v37KSgowGazAWCz2di9e7fLLpDMzEwCAgLo3LmzEXNhH1UxVX14e3vTo0cPlxiHw0FWVpYRU1OqZIiIiNQDV1xxBTfccIPLPX9/f5o1a2bcj42NJSEhgaZNmxIQEEB8fDw2m43evXsD0K9fPzp37szQoUNJTk7Gbrczbdo04uLijGrK6NGjmT9/PpMmTWLEiBGsX7+eFStWkJ6ebjw3ISGBmJgYevbsyc0338ycOXMoLS1l+PDhtXonJRkiIiIm9eJsh2rMnj0bT09PBg4cSFlZGRERESxcuNBo9/LyIi0tjSeffBKbzYa/vz8xMTHMnDnTiGnfvj3p6emMHz+euXPn0qpVK15//XUiIiKMmEGDBlFUVERiYiJ2u51u3bqRkZFx0WLQH6NzMkTqMZ2TIVI9d5+TMbeNdedkjC2o3TkZvySqZIiIiJjoW1itoYWfIiIi4haqZIiIiJiokmENJRkiIiIm9WKx4i+ApktERETELVTJEBERMXF41PUIfhmUZIiIiJhoTYY1NF0iIiIibqFKhoiIiIkWflpDSYaIiIiJQ2mGJTRdIiIiIm6hSoaIiIiJFn5aQ0mGiIiIiSZLrKEkQ0RExESVDGtoTYaIiIi4hSoZIiIiJjrx0xpKMkREREy0hdUami4RERERt1AlQ0RExER1DGsoyRARETHR7hJraLpERERE3EKVDBERERMt/LSGkgwRERETpRjW0HSJiIiIuIUqGSIiIiZa+GkNJRkiIiImWpNhDSUZIiIiJkoxrKE1GSIiIuIWqmSIiIiYaE2GNZRkiIiImDg1YWIJTZeIiIiIWyjJEBERMXFYeNXGokWLuPHGGwkICCAgIACbzcbatWuN9nPnzhEXF0ezZs1o3LgxAwcOpLCw0KWPgoICIiMjadSoEUFBQUycOJHz58+7xGzYsIHu3bvj4+NDhw4dSE1NvWgsCxYsoF27dvj6+hIWFkZOTk4t30ZJhoiIyEUcOC27aqNVq1a89NJL5Obmsn37dn73u99x3333sXfvXgDGjx/PmjVrWLlyJRs3buTo0aM88MADxucrKyuJjIykvLycLVu2sGTJElJTU0lMTDRiDh06RGRkJH379iUvL49x48YxcuRI1q1bZ8QsX76chIQEpk+fzo4dO+jatSsREREcP368Vu/j4XQ668XEk7dPq7oegki983DIzXU9BJF6aekX77q1/z+0e9iyvhYeXvE/fb5p06bMmjWLBx98kBYtWrBs2TIefPBBAPLz8+nUqRPZ2dn07t2btWvXMmDAAI4ePUpwcDAAKSkpTJ48maKiIry9vZk8eTLp6ens2bPHeEZ0dDTFxcVkZGQAEBYWRq9evZg/fz4ADoeD1q1bEx8fz5QpU2o8dlUyRERETJwWXmVlZZSUlLhcZWVlPzqGyspK3nnnHUpLS7HZbOTm5lJRUUF4eLgR07FjR9q0aUN2djYA2dnZdOnSxUgwACIiIigpKTGqIdnZ2S59VMVU9VFeXk5ubq5LjKenJ+Hh4UZMTWl3yS/MZ/uzadeu9UX3F6WkMnbsNDL/tZLf/tbm0rb4tbcYM2aq8XOPHl154YWpdL+pC06nk23b83h66gvs2r0PgLZtW3Hgs08uesZtfX5PTs4Oi99IpPbu/cMD9Lq7Ny2v/g3l58o5kJvP8pfe4tjBowA0b9WCOZtfrfaz856cRc4Hrr+RNm7SmBczZtO0ZTMe7/Io35Z8C0Cn3tfzzPLnLuojrucIThcVA+Dr78uDTz1Cz4gwApoHcHjvIZbO+BsHd31u4RuL1aw88TMpKYlnn33W5d706dOZMWNGtfG7d+/GZrNx7tw5GjduzKpVq+jcuTN5eXl4e3vTpEkTl/jg4GDsdjsAdrvdJcGoaq9q+6GYkpISzp49y6lTp6isrKw2Jj8/v1bvriTjF+aWWyPx8vIyfr7++uvIWPsO//xnunHv9Tfe5tlnXzZ+/vbbs8Y/+/s3Im3NUtLS/sUf//g0DbwakJj4FGlpb3PV1Te7LB6KuHsQ//nPZ8bPX399yl2vJVIrncKuJ/P/1nJw5+d4NfDi4UlDmPzWdCaH/5Gys2V8ffRr4nqOcPlM38F3EflEFDs3fHpRfyOT4yjIP0zTls2qfd6EO+I4e+b7X0clJ05//9k/x9HqutYsGj+X4sKT3Hr/b5ny9nQmh4/lVOFJi95Y6rOpU6eSkJDgcs/Hx+eS8ddddx15eXmcPn2af/zjH8TExLBx40Z3D9MtlGT8wpw44fqb1sSJcXz+38Ns2vT938y+/fYshYVF1X7+uus60KzZlTw782WOHDkGwPPPz2bHjg9p27YV//3vYSP25NenLtmPSF1KjnGtLrz61F9Z9Gkq7bpczf6c/+B0OIxKQ5Wed4exNX0zZd+ec7l/56MR+Af4s2reCrr17VHt80q+Pm1UNy7U0MebXvf0Zvaol9if8x8A3p2znJvCe3Ln0Aj+8fLf/4e3FHey8jAuHx+fH0wqzLy9venQoQMAPXr0YNu2bcydO5dBgwZRXl5OcXGxSzWjsLCQkJAQAEJCQi7aBVK1++TCGPOOlMLCQgICAvDz88PLywsvL69qY6r6qCmtyfgFa9iwIY8MfoAlqe+43B8cfT9Hv9rFpzs+5PnnpuDn52u0ffbZfzlx4iTDHxtMw4YN8fX15bHh0ezb9xmHD3/p0s8///kmR77M46P17zJgwF0/yzuJ/BSNrmgEQGnxmWrb291wFe2uv4qNy7Nc7ode04r7xz5MSsI8nI5Ll89f+OAvzN/2BpOXTueanh2N+14NPPFq4EVFWblLfPm5cq7r2emnvo78DJwW/u9/5XA4KCsro0ePHjRs2JCsrO//O92/fz8FBQXYbN9Ng9tsNnbv3u2yCyQzM5OAgAA6d+5sxFzYR1VMVR/e3t706NHDJcbhcJCVlWXE1JQqGb9g9/0+giZNAvi/t1Ya995ZvpqCgiMcO1pIly6deOGFp7n22qt5eNAoAM6cKeWuux5i5T/e4OmnxwLw+eeHiBwwhMrKSiNm4qRn2bJlOw6Hgwfu788/Vr7Bgw/FkpaW+fO/qMgP8PDw4NHpI9i/bR9HPiuoNuaO6HC+OvAlB3L3G/caeDcgbl4Cf39xCV8fPUFQm+CLPld8/BR/m5rCwV2f09CnIXdEh/PMOzOZETWFw3sOcq70HJ/l5hMV/xBfHTjC6ROnueW+27im+7UUHra77Z3lf1dXx4pPnTqVe+65hzZt2vDNN9+wbNkyNmzYwLp16wgMDCQ2NpaEhASaNm1KQEAA8fHx2Gw2evfuDUC/fv3o3LkzQ4cOJTk5GbvdzrRp04iLizOqKaNHj2b+/PlMmjSJESNGsH79elasWEF6+vfT6gkJCcTExNCzZ09uvvlm5syZQ2lpKcOHD6/V+1ieZHz55ZdMnz6dv/3tb5eMKSsru2hlrdPpxMPDw+rh/Ko9Njyades+4tix70teb7zxtvHPe/bmc8xeyL/WreCqq9py8OAX+Pr68uqrL5O9ZRtDh8bh5eVFwvgneG/1Emy3DODcuXN8/fUp5s59zegnN3cnLVsGkzB+tJIMqXdinhtFq2vb8NyDz1Tb3tDHG9vv+7D6rytd7g+a/ChHPz/C5lWbLtn3sYNHjcWkAAdy9xPUJoS7YweQMn4eACnj5jJq1hjmb3uDyvOVHN5zkOz3P6Zdl6steDv5pTl+/DjDhg3j2LFjBAYGcuONN7Ju3Truuuu7avHs2bPx9PRk4MCBlJWVERERwcKFC43Pe3l5kZaWxpNPPonNZsPf35+YmBhmzpxpxLRv35709HTGjx/P3LlzadWqFa+//joRERFGzKBBgygqKiIxMRG73U63bt3IyMi4aDHoj7H8nIydO3fSvXt342+91ZkxY8ZFK209Pa/Aq0GAlUP5VWvT5jfsz9/Cw4NGsWbNvy4Z16iRH8WnDhA5YAiZmRt57LFonps5mTZtu1P1n0bDhg05XriXJ56YwIqV71fbz+jRMUyd8kfatqt+zlp+Gp2T8b8ZNnMkPe66mecfnkbRl9UfInTr/b9lVPIfiA8bxTcnS4z7L3zwCq07tqHqd0gPD/D08qLyfCXvzf8H785eXm1/g58exrW9OvHs/VNd7vv4+eB3RSOKj59izPyn8PX35eXhL1jzor9C7j4nY3i7gZb19ebhf1rW1+Wm1pWM99+v/g+ZKgcPHvzRPqpbadusueYnrRQzbBDHj5/ggw+yfjCua9frAbAf++434EaN/HA4HFyYe1b97Ol56SU8XW+8Hru9difBibjTsJkj6RkRxguDEi+ZYADcMehOdny43SXBAJg7Ohlv3+8X613VtQOPvzyG5x56huNfFJq7MbTp3J7i4xfvtCo7W0bZ2TIaBfjT5fZuvJP0fz/hreTnom9htUatk4yoqCg8PDz4oQLIj017VLfSVlMl1vHw8GDYsIdZuvQfLhWlq65qS/SgKNZmrOfkyVN06dKJWbOms2nTJ+ze890ZGFlZm3gp6RnmzXuBhQvfxNPDk4kT4zh//jwbNm4BYOijD1JeXkHezu9Oi4u67x4ee2wQT4ye+PO/rEg1Hnv+cWy/78PsUUmcKz1LYIsmAHxb8q3LIszgtiFcF9aZlx+7uKJwvMA1kbii6RUAHP38iLGTJGLEAIq+LOSrz76koY83d0SHc/0tN/Dnod+Xprvc3g0PDw+OHfyK4LYtGfz0MI799ys2rVxv9WuL1Du1TjJatmzJwoULue+++6ptz8vLo0cPlczr0p139qFt21akLnHdVVJeXs7vfteH+PiR+Pv78eWRY6xetZYXk+YaMfv3/5f7HxjOtGfGs2njezgcTvJ27mHAvUNdKhVPPz2WNm1acf78efbv/y9DhvyBd1elI1IfhA+9G4BpK553uf/qU3/l3//4yPj5tw/fycljX7N7U95Pek6Dhg0YMu0xrgxpStnZcr7MP0zSkGfZl/39cc2NrmjEw5MfpWlIM0pPnyFnbTYrZy2j8vylp5Sl7jnqxzduXPZqvSbj97//Pd26dXNZRHKhnTt3ctNNN+Fw1K7YpO8uEbmY1mSIVM/dazIebfvAjwfVkLvHWp/VupIxceJESktLL9neoUMHPvroo0u2i4iIyK9DrZOMPn36/GC7v78/v/3tb3/ygEREROqald9d8mumw7hERERMrDipU3SsuIiIiLiJKhkiIiImOifDGkoyRERETLQmwxpKMkREREy0JsMaWpMhIiIibqFKhoiIiInWZFhDSYaIiIiJxV9Q/qul6RIRERFxC1UyRERETLS7xBpKMkREREy0JsMami4RERERt1AlQ0RExETnZFhDSYaIiIiJ1mRYQ9MlIiIi4haqZIiIiJjonAxrKMkQEREx0e4SayjJEBERMdHCT2toTYaIiIi4hSoZIiIiJtpdYg0lGSIiIiZa+GkNTZeIiIiIW6iSISIiYqLpEmsoyRARETHR7hJraLpERERE3EJJhoiIiInD6bTsqo2kpCR69erFFVdcQVBQEFFRUezfv98l5ty5c8TFxdGsWTMaN27MwIEDKSwsdIkpKCggMjKSRo0aERQUxMSJEzl//rxLzIYNG+jevTs+Pj506NCB1NTUi8azYMEC2rVrh6+vL2FhYeTk5NTqfZRkiIiImDgtvGpj48aNxMXF8cknn5CZmUlFRQX9+vWjtLTUiBk/fjxr1qxh5cqVbNy4kaNHj/LAAw8Y7ZWVlURGRlJeXs6WLVtYsmQJqampJCYmGjGHDh0iMjKSvn37kpeXx7hx4xg5ciTr1q0zYpYvX05CQgLTp09nx44ddO3alYiICI4fP17j9/Fw1pN9Ot4+rep6CCL1zsMhN9f1EETqpaVfvOvW/vv85k7L+vr3V1k/+bNFRUUEBQWxceNGbr/9dk6fPk2LFi1YtmwZDz74IAD5+fl06tSJ7Oxsevfuzdq1axkwYABHjx4lODgYgJSUFCZPnkxRURHe3t5MnjyZ9PR09uzZYzwrOjqa4uJiMjIyAAgLC6NXr17Mnz8fAIfDQevWrYmPj2fKlCk1Gr8qGSIiIiYOnJZdZWVllJSUuFxlZWU1Gsfp06cBaNq0KQC5ublUVFQQHh5uxHTs2JE2bdqQnZ0NQHZ2Nl26dDESDICIiAhKSkrYu3evEXNhH1UxVX2Ul5eTm5vrEuPp6Ul4eLgRUxNKMkREREysTDKSkpIIDAx0uZKSkn58DA4H48aN49Zbb+WGG24AwG634+3tTZMmTVxig4ODsdvtRsyFCUZVe1XbD8WUlJRw9uxZTpw4QWVlZbUxVX3UhLawioiImFi5kmDq1KkkJCS43PPx8fnRz8XFxbFnzx4+/vhjy8byc1OSISIi4kY+Pj41SiouNGbMGNLS0ti0aROtWn2/ZjEkJITy8nKKi4tdqhmFhYWEhIQYMeZdIFW7Ty6MMe9IKSwsJCAgAD8/P7y8vPDy8qo2pqqPmtB0iYiIiImV0yW14XQ6GTNmDKtWrWL9+vW0b9/epb1Hjx40bNiQrKzvF5Pu37+fgoICbDYbADabjd27d7vsAsnMzCQgIIDOnTsbMRf2URVT1Ye3tzc9evRwiXE4HGRlZRkxNaFKhoiIiEldnfgZFxfHsmXLeO+997jiiiuM9Q+BgYH4+fkRGBhIbGwsCQkJNG3alICAAOLj47HZbPTu3RuAfv360blzZ4YOHUpycjJ2u51p06YRFxdnVFRGjx7N/PnzmTRpEiNGjGD9+vWsWLGC9PR0YywJCQnExMTQs2dPbr75ZubMmUNpaSnDhw+v8fsoyRAREaknFi1aBMAdd9zhcv/NN9/kscceA2D27Nl4enoycOBAysrKiIiIYOHChUasl5cXaWlpPPnkk9hsNvz9/YmJiWHmzJlGTPv27UlPT2f8+PHMnTuXVq1a8frrrxMREWHEDBo0iKKiIhITE7Hb7XTr1o2MjIyLFoP+EJ2TIVKP6ZwMkeq5+5yMni37WNbX9mP/tqyvy40qGSIiIib6FlZraOGniIiIuIUqGSIiIib1ZCXBZU9JhoiIiImmS6yh6RIRERFxC1UyRERETOrqnIxfGiUZIiIiJg6tybCEkgwRERETVTKsoTUZIiIi4haqZIiIiJhousQaSjJERERMNF1iDU2XiIiIiFuokiEiImKi6RJrKMkQEREx0XSJNTRdIiIiIm6hSoaIiIiJpkusoSRDRETERNMl1tB0iYiIiLiFKhkiIiImTqejrofwi6AkQ0RExMSh6RJLKMkQERExcWrhpyW0JkNERETcQpUMERERE02XWENJhoiIiImmS6yh6RIRERFxC1UyRERETHTipzWUZIiIiJjoxE9raLpERERE3EKVDBERERMt/LSGkgwRERETbWG1hqZLRERExC2UZIiIiJg4nU7LrtrYtGkT9957L6GhoXh4eLB69eqLxpWYmEjLli3x8/MjPDycAwcOuMScPHmSIUOGEBAQQJMmTYiNjeXMmTMuMbt27aJPnz74+vrSunVrkpOTLxrLypUr6dixI76+vnTp0oUPPvigVu8CSjJEREQu4nA6Lbtqo7S0lK5du7JgwYJq25OTk5k3bx4pKSls3boVf39/IiIiOHfunBEzZMgQ9u7dS2ZmJmlpaWzatInHH3/caC8pKaFfv360bduW3NxcZs2axYwZM1i8eLERs2XLFgYPHkxsbCyffvopUVFRREVFsWfPnlq9j4eznqxu8fZpVddDEKl3Hg65ua6HIFIvLf3iXbf2f2XjDpb1derM5z/pcx4eHqxatYqoqCjguypGaGgoTz31FBMmTADg9OnTBAcHk5qaSnR0NPv27aNz585s27aNnj17ApCRkUH//v05cuQIoaGhLFq0iGeeeQa73Y63tzcAU6ZMYfXq1eTn5wMwaNAgSktLSUtLM8bTu3dvunXrRkpKSo3fQZUMERERNyorK6OkpMTlKisrq3U/hw4dwm63Ex4ebtwLDAwkLCyM7OxsALKzs2nSpImRYACEh4fj6enJ1q1bjZjbb7/dSDAAIiIi2L9/P6dOnTJiLnxOVUzVc2pKSYaIiIiJA6dlV1JSEoGBgS5XUlJSrcdkt9sBCA4OdrkfHBxstNntdoKCglzaGzRoQNOmTV1iquvjwmdcKqaqvaa0hVVERMTEypUEU6dOJSEhweWej4+PZf3XZ0oyRERE3MjHx8eSpCIkJASAwsJCWrZsadwvLCykW7duRszx48ddPnf+/HlOnjxpfD4kJITCwkKXmKqffyymqr2mNF0iIiJiUle7S35I+/btCQkJISsry7hXUlLC1q1bsdlsANhsNoqLi8nNzTVi1q9fj8PhICwszIjZtGkTFRUVRkxmZibXXXcdV155pRFz4XOqYqqeU1NKMkREREycFv6vNs6cOUNeXh55eXnAd4s98/LyKCgowMPDg3HjxvH888/z/vvvs3v3boYNG0ZoaKixA6VTp07cfffdjBo1ipycHDZv3syYMWOIjo4mNDQUgEceeQRvb29iY2PZu3cvy5cvZ+7cuS5TOmPHjiUjI4NXXnmF/Px8ZsyYwfbt2xkzZkyt3kdbWEXqMW1hFameu7ew+jdqZ1lfpd8ernHshg0b6Nu370X3Y2JiSE1Nxel0Mn36dBYvXkxxcTG33XYbCxcu5NprrzViT548yZgxY1izZg2enp4MHDiQefPm0bhxYyNm165dxMXFsW3bNpo3b058fDyTJ092eebKlSuZNm0ahw8f5pprriE5OZn+/fvX6t2VZIjUY0oyRKrn7iTDz6+tZX2dPfuFZX1dbrTwU0RExKSe/P37sqc1GSIiIuIWqmSIiIiY1HbBplRPSYaIiIiJpkusoSRDRETEREmGNbQmQ0RERNxClQwRERET1TGsUW/OyZD6oaysjKSkJKZOnfqr+QIfkR+jXxciP42SDHFRUlJCYGAgp0+fJiAgoK6HI1Iv6NeFyE+jNRkiIiLiFkoyRERExC2UZIiIiIhbKMkQFz4+PkyfPl2L20QuoF8XIj+NFn6KiIiIW6iSISIiIm6hJENERETcQkmGiIiIuIWSDBEREXELJRliWLBgAe3atcPX15ewsDBycnLqekgidWrTpk3ce++9hIaG4uHhwerVq+t6SCKXFSUZAsDy5ctJSEhg+vTp7Nixg65duxIREcHx48fremgidaa0tJSuXbuyYMGCuh6KyGVJW1gFgLCwMHr16sX8+fMBcDgctG7dmvj4eKZMmVLHoxOpex4eHqxatYqoqKi6HorIZUOVDKG8vJzc3FzCw8ONe56enoSHh5OdnV2HIxMRkcuZkgzhxIkTVFZWEhwc7HI/ODgYu91eR6MSEZHLnZIMERERcQslGULz5s3x8vKisLDQ5X5hYSEhISF1NCoREbncKckQvL296dGjB1lZWcY9h8NBVlYWNputDkcmIiKXswZ1PQCpHxISEoiJiaFnz57cfPPNzJkzh9LSUoYPH17XQxOpM2fOnOHzzz83fj506BB5eXk0bdqUNm3a1OHIRC4P2sIqhvnz5zNr1izsdjvdunVj3rx5hIWF1fWwROrMhg0b6Nu370X3Y2JiSE1N/fkHJHKZUZIhIiIibqE1GSIiIuIWSjJERETELZRkiIiIiFsoyRARERG3UJIhIiIibqEkQ0RERNxCSYaIiIi4hZIMERERcQslGSIiIuIWSjJERETELZRkiIiIiFsoyRARERG3+H9wZBfKRZDG4QAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#random forest classifier with n_estimators=100 (default)\n",
    "clf_rf = RandomForestClassifier(random_state=43)      \n",
    "clr_rf = clf_rf.fit(x_train[selected_features],y_train)\n",
    "\n",
    "y_pred = clf_rf.predict(x_test[selected_features])\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "                            \n",
    "cm = confusion_matrix(y_test,y_pred)\n",
    "sns.heatmap(cm,annot=True,fmt=\"d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "72b44a7e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T19:23:50.171500Z",
     "iopub.status.busy": "2024-05-13T19:23:50.170672Z",
     "iopub.status.idle": "2024-05-13T19:23:58.221813Z",
     "shell.execute_reply": "2024-05-13T19:23:58.220983Z"
    },
    "papermill": {
     "duration": 8.140205,
     "end_time": "2024-05-13T19:23:58.223990",
     "exception": false,
     "start_time": "2024-05-13T19:23:50.083785",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7636394776094806"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_prob = clf_rf.predict_proba(x_test[selected_features])[:, 1]\n",
    "pred_df = pd.DataFrame(y_pred_prob, columns=['prediction'])\n",
    "true_df = pd.DataFrame(y_test, columns=['target']).reset_index(drop=True)\n",
    "\n",
    "amex_metric(true_df, pred_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455fab1e",
   "metadata": {
    "papermill": {
     "duration": 0.079927,
     "end_time": "2024-05-13T19:23:58.384053",
     "exception": false,
     "start_time": "2024-05-13T19:23:58.304126",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**XGBoost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8b9281d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T19:23:58.547057Z",
     "iopub.status.busy": "2024-05-13T19:23:58.546334Z",
     "iopub.status.idle": "2024-05-13T19:25:30.830690Z",
     "shell.execute_reply": "2024-05-13T19:25:30.829788Z"
    },
    "papermill": {
     "duration": 92.404114,
     "end_time": "2024-05-13T19:25:30.868693",
     "exception": false,
     "start_time": "2024-05-13T19:23:58.464579",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93    101094\n",
      "           1       0.81      0.80      0.80     35044\n",
      "\n",
      "    accuracy                           0.90    136138\n",
      "   macro avg       0.87      0.87      0.87    136138\n",
      "weighted avg       0.90      0.90      0.90    136138\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# XGBoost classifier\n",
    "import xgboost as xgb\n",
    "clf_xgb = xgb.XGBClassifier(random_state=43)\n",
    "clf_xgb.fit(x_train[selected_features], y_train)\n",
    "\n",
    "y_pred = clf_xgb.predict(x_test[selected_features])\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c0a2bd53",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T19:25:31.030516Z",
     "iopub.status.busy": "2024-05-13T19:25:31.029776Z",
     "iopub.status.idle": "2024-05-13T19:25:32.428955Z",
     "shell.execute_reply": "2024-05-13T19:25:32.427801Z"
    },
    "papermill": {
     "duration": 1.483841,
     "end_time": "2024-05-13T19:25:32.431613",
     "exception": false,
     "start_time": "2024-05-13T19:25:30.947772",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7779548067340316"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_prob = clf_xgb.predict_proba(x_test[selected_features])[:, 1]\n",
    "pred_df = pd.DataFrame(y_pred_prob, columns=['prediction'])\n",
    "true_df = pd.DataFrame(y_test, columns=['target']).reset_index(drop=True)\n",
    "\n",
    "amex_metric(true_df, pred_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60cb154c",
   "metadata": {
    "papermill": {
     "duration": 0.07913,
     "end_time": "2024-05-13T19:25:32.590721",
     "exception": false,
     "start_time": "2024-05-13T19:25:32.511591",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1a5e744d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T19:25:32.754472Z",
     "iopub.status.busy": "2024-05-13T19:25:32.753998Z",
     "iopub.status.idle": "2024-05-13T19:25:46.694731Z",
     "shell.execute_reply": "2024-05-13T19:25:46.693652Z"
    },
    "papermill": {
     "duration": 14.024157,
     "end_time": "2024-05-13T19:25:46.696928",
     "exception": false,
     "start_time": "2024-05-13T19:25:32.672771",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.93      0.91    101094\n",
      "           1       0.78      0.69      0.73     35044\n",
      "\n",
      "    accuracy                           0.87    136138\n",
      "   macro avg       0.84      0.81      0.82    136138\n",
      "weighted avg       0.87      0.87      0.87    136138\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Logistic Regression classifier\n",
    "clf_lr = LogisticRegression(random_state=43)\n",
    "clf_lr.fit(x_train[selected_features], y_train)\n",
    "\n",
    "y_pred = clf_lr.predict(x_test[selected_features])\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d90318ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T19:25:46.858805Z",
     "iopub.status.busy": "2024-05-13T19:25:46.858390Z",
     "iopub.status.idle": "2024-05-13T19:25:47.448117Z",
     "shell.execute_reply": "2024-05-13T19:25:47.446843Z"
    },
    "papermill": {
     "duration": 0.673634,
     "end_time": "2024-05-13T19:25:47.450515",
     "exception": false,
     "start_time": "2024-05-13T19:25:46.776881",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6867284661819631"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_prob = clf_lr.predict_proba(x_test[selected_features])[:, 1]\n",
    "pred_df = pd.DataFrame(y_pred_prob, columns=['prediction'])\n",
    "true_df = pd.DataFrame(y_test, columns=['target']).reset_index(drop=True)\n",
    "\n",
    "amex_metric(true_df, pred_df)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 3723648,
     "sourceId": 35332,
     "sourceType": "competition"
    },
    {
     "datasetId": 2231132,
     "sourceId": 3739819,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30698,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 20854.039375,
   "end_time": "2024-05-13T19:25:49.029986",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-05-13T13:38:14.990611",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
